{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting memory_profiler\n",
      "  Downloading https://files.pythonhosted.org/packages/f4/03/175d380294b2333b9b79c2f2aa235eb90ee95e3ddef644497a9455404312/memory_profiler-0.57.0.tar.gz\n",
      "Collecting psutil\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/3e/d18f2c04cf2b528e18515999b0c8e698c136db78f62df34eee89cee205f1/psutil-5.7.2.tar.gz (460kB)\n",
      "\u001b[K     |████████████████████████████████| 460kB 11.0MB/s eta 0:00:01     |██████████▊                     | 153kB 11.0MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: memory-profiler, psutil\n",
      "  Building wheel for memory-profiler (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for memory-profiler: filename=memory_profiler-0.57.0-cp36-none-any.whl size=28995 sha256=a328c2ddc586c4c8b9bb3658b30db464abbf31030e146fbc53cff7f607e5b560\n",
      "  Stored in directory: /home/as3837/.cache/pip/wheels/74/20/b5/20964ef97be73d2c3a695c9cad7bccd96d1e3e737a8163861f\n",
      "  Building wheel for psutil (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for psutil: filename=psutil-5.7.2-cp36-cp36m-linux_x86_64.whl size=263531 sha256=eb88138c042b6afb1cfbfe1b83f4665b1b4d3e941649830c077484b89b3d760e\n",
      "  Stored in directory: /home/as3837/.cache/pip/wheels/39/a0/f5/c4fa280463e29aea07797acb5312358fefb067c1f4f98e11b1\n",
      "Successfully built memory-profiler psutil\n",
      "Installing collected packages: psutil, memory-profiler\n",
      "Successfully installed memory-profiler-0.57.0 psutil-5.7.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.spatial import KDTree\n",
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd.variable import Variable\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix seeds for reproducibility. Note that the results may not be reproducible even if seeds are fixed if the device changes\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available else torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_dist = []\n",
    "\n",
    "\n",
    "for i in range(50): \n",
    "    m = torch.distributions.multivariate_normal.MultivariateNormal(torch.zeros(2), torch.eye(2))\n",
    "    x = m.sample([250])\n",
    "    set_dist.append(x) \n",
    "    \n",
    "for i in range(50): \n",
    "    m = torch.distributions.multivariate_normal.MultivariateNormal(torch.tensor([0.0, 1.0]), torch.tensor([[1,.5],[.5,1]]))\n",
    "    x = m.sample([250])\n",
    "    set_dist.append(x) \n",
    "    \n",
    "for i in range(50): \n",
    "    m = torch.distributions.multivariate_normal.MultivariateNormal(torch.ones(2), covariance_matrix=torch.tensor([[.7,.1],[.1,1]]))\n",
    "    x = m.sample([250])\n",
    "    set_dist.append(x) \n",
    "    \n",
    "for i in range(50): \n",
    "    m = torch.distributions.multivariate_normal.MultivariateNormal(torch.tensor([1.0, 0.0]), torch.tensor([[.2, -.1], [-.1, 1]]))\n",
    "    x = m.sample([250])\n",
    "    set_dist.append(x) \n",
    "    \n",
    "for i in range(50): \n",
    "    m = torch.distributions.multivariate_normal.MultivariateNormal(torch.tensor([.5, .5]), torch.tensor([[.8,.4],[.4,1]]))\n",
    "    x = m.sample([250])\n",
    "    set_dist.append(x) \n",
    "    \n",
    "for i in range(50): \n",
    "    m = torch.distributions.multivariate_normal.MultivariateNormal(torch.tensor([-.25, -.5]), torch.eye(2)*.5)\n",
    "    x = m.sample([250])\n",
    "    set_dist.append(x) \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_dist = torch.stack(set_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300, 250, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Set2Set(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, act_fn=nn.Tanh, num_layers=1):\n",
    "        '''\n",
    "        Args:\n",
    "            input_dim: input dim of Set2Set. \n",
    "            hidden_dim: the dim of set representation, which is also the INPUT dimension of \n",
    "                the LSTM in Set2Set. \n",
    "                This is a concatenation of weighted sum of embedding (dim input_dim), and the LSTM\n",
    "                hidden/output (dim: self.lstm_output_dim).\n",
    "        '''\n",
    "        super(Set2Set, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        if hidden_dim <= input_dim:\n",
    "            print('ERROR: Set2Set output_dim should be larger than input_dim')\n",
    "        # the hidden is a concatenation of weighted sum of embedding and LSTM output\n",
    "        self.lstm_output_dim = hidden_dim - input_dim\n",
    "        self.lstm = nn.LSTM(hidden_dim, input_dim, num_layers=num_layers, batch_first=True)\n",
    "\n",
    "        # convert back to dim of input_dim\n",
    "       # self.pred = nn.Linear(hidden_dim, input_dim)\n",
    "        self.pred = nn.Linear(hidden_dim,4)\n",
    "        self.act = act_fn()\n",
    "\n",
    "    def forward(self, embedding):\n",
    "        '''\n",
    "        Args:\n",
    "            embedding: [batch_size x n x d] embedding matrix\n",
    "        Returns:\n",
    "            aggregated: [batch_size x d] vector representation of all embeddings\n",
    "        '''\n",
    "        batch_size = embedding.size()[0]\n",
    "        n = embedding.size()[1]\n",
    "\n",
    "        hidden = (torch.zeros(self.num_layers, batch_size, self.lstm_output_dim).cuda(),\n",
    "                  torch.zeros(self.num_layers, batch_size, self.lstm_output_dim).cuda())\n",
    "\n",
    "        q_star = torch.zeros(batch_size, 1, self.hidden_dim).cuda()\n",
    "        for i in range(n):\n",
    "            # q: batch_size x 1 x input_dim\n",
    "            q, hidden = self.lstm(q_star, hidden)\n",
    "            # e: batch_size x n x 1\n",
    "            e = embedding @ torch.transpose(q, 1, 2)\n",
    "            a = nn.Softmax(dim=1)(e)\n",
    "            r = torch.sum(a * embedding, dim=1, keepdim=True)\n",
    "            q_star = torch.cat((q, r), dim=2)\n",
    "        q_star = torch.squeeze(q_star, dim=1)\n",
    "        out = self.act(self.pred(q_star))\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For future experiments should increase the output dim to at least 5.\n",
    "class DeepSet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, set_features):\n",
    "        super(DeepSet, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = set_features\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Linear(in_features, 50),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Linear(50, 100),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Linear(100, set_features)\n",
    "        )\n",
    "\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(set_features, 30),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Linear(30, 30),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Linear(30, 10),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Linear(10, 2),\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, input):\n",
    "        x = input\n",
    "        x = self.feature_extractor(x)\n",
    "        x = x.sum(dim=1)\n",
    "        x = self.regressor(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\" Set Encoder \n",
    "    \"\"\"\n",
    "    def __init__(self, dim_Q, dim_K, dim_V, d_model, num_heads, ln=False, skip=True):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.dim_V = dim_V\n",
    "        self.num_heads = num_heads\n",
    "        self.skip = skip\n",
    "       # self.s_max = s_max\n",
    "        #Maximum set size\n",
    "        self.d_model = d_model\n",
    "        self.fc_q = nn.Linear(dim_Q, d_model)\n",
    "        self.fc_k = nn.Linear(dim_K, d_model)\n",
    "        self.fc_v = nn.Linear(dim_K, d_model)\n",
    "        if ln:\n",
    "            self.ln0 = nn.LayerNorm(d_model)\n",
    "            self.ln1 = nn.LayerNorm(d_model)\n",
    "        #This is the classic pointwise feedforward in \"Attention is All you need\"\n",
    "        self.ff = nn.Sequential(\n",
    "        nn.Linear(d_model, 4 * d_model),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(4 * d_model, d_model))\n",
    "        # I have experimented with just a smaller version of this \n",
    "       # self.fc_o = nn.Linear(d_model,d_model)\n",
    "        \n",
    "     #   self.fc_rep = nn.Linear(s_max, 1)\n",
    "#number of heads must divide output size = d_model\n",
    "        \n",
    "\n",
    "    def forward(self, Q, K):\n",
    "        Q = self.fc_q(Q)\n",
    "      \n",
    "        K, V = self.fc_k(K), self.fc_v(K)\n",
    "\n",
    "        dim_split = self.d_model // self.num_heads\n",
    "        Q_ = torch.cat(Q.split(dim_split, 2), 0)\n",
    "        K_ = torch.cat(K.split(dim_split, 2), 0)\n",
    "        V_ = torch.cat(V.split(dim_split, 2), 0)\n",
    "  \n",
    "\n",
    "        A = torch.softmax(Q_.bmm(K_.transpose(-2,-1))/math.sqrt(self.d_model), dim=-1)\n",
    "        A_1 = A.bmm(V_)\n",
    "        \n",
    " \n",
    "        O = torch.cat((A_1).split(Q.size(0), 0), 2)\n",
    "       \n",
    "        O = torch.cat((Q_ + A_1).split(Q.size(0), 0), 2) if getattr(self, 'skip', True) else \\\n",
    "             torch.cat((A_1).split(Q.size(0), 0), 2)\n",
    "        O = O if getattr(self, 'ln0', None) is None else self.ln0(O)\n",
    "       # O = O + F.relu(self.fc_o(O)) if getattr(self, 'skip', None) is None else F.relu(self.fc_o(O))\n",
    "        # For the classic transformers paper it is \n",
    "        O = O + self.ff(O)\n",
    "        O = O if getattr(self, 'ln1', None) is None else self.ln1(O)\n",
    "        O = torch.mean(O,dim=1)\n",
    "#         O = pad_sequence(O, batch_first=True, padding_value=0)\n",
    "#         O = O.transpose(-2,-1)\n",
    "#         O = F.pad(O, (0, self.s_max- O.shape[-1]), 'constant', 0)\n",
    "      #  O = self.fc_rep(O)\n",
    "       # O = self.fc_rep(O.transpose(-2,-1))\n",
    "      #  O = O.squeeze()\n",
    "\n",
    "        return O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, dim_in=18, dim_out=8, num_heads=2, ln=True, skip=True):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.Encoder = Encoder(dim_in, dim_in, dim_in, dim_out, num_heads, ln=ln, skip=skip)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.Encoder(X, X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-15\n",
    "\"\"\"Approximating KL divergences between two probability densities using samples. \n",
    "    It is buggy. Use at your own peril\n",
    "\"\"\"\n",
    "\n",
    "def knn_distance(point, sample, k):\n",
    "    \"\"\" Euclidean distance from `point` to it's `k`-Nearest\n",
    "    Neighbour in `sample` \"\"\"\n",
    "    norms = np.linalg.norm(sample-point, axis=1)\n",
    "    return np.sort(norms)[k]\n",
    "\n",
    "\n",
    "def verify_sample_shapes(s1, s2, k):\n",
    "    # Expects [N, D]\n",
    "    assert(len(s1.shape) == len(s2.shape) == 2)\n",
    "    # Check dimensionality of sample is identical\n",
    "    assert(s1.shape[1] == s2.shape[1])\n",
    "\n",
    "\n",
    "def naive_estimator(s1, s2, k=1):\n",
    "    \"\"\" KL-Divergence estimator using brute-force (numpy) k-NN\n",
    "        s1: (N_1,D) Sample drawn from distribution P\n",
    "        s2: (N_2,D) Sample drawn from distribution Q\n",
    "        k: Number of neighbours considered (default 1)\n",
    "        return: estimated D(P|Q)\n",
    "    \"\"\"\n",
    "    verify_sample_shapes(s1, s2, k)\n",
    "\n",
    "    n, m = len(s1), len(s2)\n",
    "    D = np.log(m / (n - 1))\n",
    "    d = float(s1.shape[1])\n",
    "\n",
    "    for p1 in s1:\n",
    "        nu = knn_distance(p1, s2, k-1)  # -1 because 'p1' is not in 's2'\n",
    "        rho = knn_distance(p1, s1, k)\n",
    "        D += (d/n)*np.log((nu/rho)+eps)\n",
    "    return D\n",
    "\n",
    "\n",
    "def scipy_estimator(s1, s2, k=1):\n",
    "    \"\"\" KL-Divergence estimator using scipy's KDTree\n",
    "        s1: (N_1,D) Sample drawn from distribution P\n",
    "        s2: (N_2,D) Sample drawn from distribution Q\n",
    "        k: Number of neighbours considered (default 1)\n",
    "        return: estimated D(P|Q)\n",
    "    \"\"\"\n",
    "    verify_sample_shapes(s1, s2, k)\n",
    "\n",
    "    n, m = len(s1), len(s2)\n",
    "    d = float(s1.shape[1])\n",
    "    D = np.log(m / (n - 1))\n",
    "\n",
    "    nu_d,  nu_i   = KDTree(s2).query(s1, k)\n",
    "    rho_d, rhio_i = KDTree(s1).query(s1, k+1)\n",
    "\n",
    "    # KTree.query returns different shape in k==1 vs k > 1\n",
    "    if k > 1:\n",
    "        D += (d/n)*np.sum(np.log(nu_d[::, -1]/rho_d[::, -1]))\n",
    "    else:\n",
    "        D += (d/n)*np.sum(np.log(nu_d/rho_d[::, -1]))\n",
    "\n",
    "    return D\n",
    "\n",
    "\n",
    "def skl_estimator(s1, s2, k=1):\n",
    "    \"\"\" KL-Divergence estimator using scikit-learn's NearestNeighbours\n",
    "        s1: (N_1,D) Sample drawn from distribution P\n",
    "        s2: (N_2,D) Sample drawn from distribution Q\n",
    "        k: Number of neighbours considered (default 1)\n",
    "        return: estimated D(P|Q)\n",
    "    \"\"\"\n",
    "    verify_sample_shapes(s1, s2, k)\n",
    "\n",
    "    n, m = len(s1), len(s2)\n",
    "    d = float(s1.shape[1])\n",
    "    D = np.log(m / (n - 1))\n",
    "\n",
    "    s1_neighbourhood = NearestNeighbors(k+1, 10).fit(s1)\n",
    "    s2_neighbourhood = NearestNeighbors(k, 10).fit(s2)\n",
    "\n",
    "    for p1 in s1:\n",
    "        s1_distances, indices = s1_neighbourhood.kneighbors([p1], k+1)\n",
    "        s2_distances, indices = s2_neighbourhood.kneighbors([p1], k)\n",
    "        rho = s1_distances[0][-1]\n",
    "        nu = s2_distances[0][-1]\n",
    "        D += (d/n)*np.log(nu/rho)\n",
    "    return D\n",
    "\n",
    "\n",
    "# List of all estimators\n",
    "Estimators = [naive_estimator, scipy_estimator, skl_estimator]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinkhornDistance(nn.Module):\n",
    "    r\"\"\"\n",
    "    Given two empirical measures each with :math:`P_1` locations\n",
    "    :math:`x\\in\\mathbb{R}^{D_1}` and :math:`P_2` locations :math:`y\\in\\mathbb{R}^{D_2}`,\n",
    "    outputs an approximation of the regularized OT cost for point clouds.\n",
    "    Args:\n",
    "        eps (float): regularization coefficient\n",
    "        max_iter (int): maximum number of Sinkhorn iterations\n",
    "        reduction (string, optional): Specifies the reduction to apply to the output:\n",
    "            'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n",
    "            'mean': the sum of the output will be divided by the number of\n",
    "            elements in the output, 'sum': the output will be summed. Default: 'none'\n",
    "    Shape:\n",
    "        - Input: :math:`(N, P_1, D_1)`, :math:`(N, P_2, D_2)`\n",
    "        - Output: :math:`(N)` or :math:`()`, depending on `reduction`\n",
    "    \"\"\"\n",
    "    def __init__(self, eps, max_iter, reduction='none'):\n",
    "        super(SinkhornDistance, self).__init__()\n",
    "        self.eps = eps\n",
    "        self.max_iter = max_iter\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        # The Sinkhorn algorithm takes as input three variables :\n",
    "        C = self._cost_matrix(x, y)  # Wasserstein cost function\n",
    "        x_points = x.shape[-2]\n",
    "        y_points = y.shape[-2]\n",
    "        if x.dim() == 2:\n",
    "            batch_size = 1\n",
    "        else:\n",
    "            batch_size = x.shape[0]\n",
    "\n",
    "        # both marginals are fixed with equal weights\n",
    "        mu = torch.empty(batch_size, x_points, dtype=torch.float,\n",
    "                         requires_grad=False).fill_(1.0 / x_points).to(device).squeeze()\n",
    "        nu = torch.empty(batch_size, y_points, dtype=torch.float,\n",
    "                         requires_grad=False).fill_(1.0 / y_points).to(device).squeeze()\n",
    "\n",
    "        u = torch.zeros_like(mu).to(device)\n",
    "        v = torch.zeros_like(nu).to(device)\n",
    "        # To check if algorithm terminates because of threshold\n",
    "        # or max iterations reached\n",
    "        actual_nits = 0\n",
    "        # Stopping criterion\n",
    "        thresh = 1e-1\n",
    "\n",
    "        # Sinkhorn iterations\n",
    "        for i in range(self.max_iter):\n",
    "            u1 = u  # useful to check the update\n",
    "            u = self.eps * (torch.log(mu+1e-8) - torch.logsumexp(self.M(C, u, v), dim=-1)) + u\n",
    "            v = self.eps * (torch.log(nu+1e-8) - torch.logsumexp(self.M(C, u, v).transpose(-2, -1), dim=-1)) + v\n",
    "            err = (u - u1).abs().sum(-1).mean()\n",
    "\n",
    "            actual_nits += 1\n",
    "            if err.item() < thresh:\n",
    "                break\n",
    "\n",
    "        U, V = u, v\n",
    "        # Transport plan pi = diag(a)*K*diag(b)\n",
    "        pi = torch.exp(self.M(C, U, V))\n",
    "        # Sinkhorn distance\n",
    "        cost = torch.sum(pi * C, dim=(-2, -1))\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            cost = cost.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            cost = cost.sum()\n",
    "\n",
    "      #  return cost, pi, C\n",
    "        return cost\n",
    "\n",
    "    def M(self, C, u, v):\n",
    "        \"Modified cost for logarithmic updates\"\n",
    "        \"$M_{ij} = (-c_{ij} + u_i + v_j) / \\epsilon$\"\n",
    "        return (-C + u.unsqueeze(-1) + v.unsqueeze(-2)) / self.eps\n",
    "\n",
    "    @staticmethod\n",
    "    def _cost_matrix(x, y, p=2):\n",
    "        \"Returns the matrix of $|x_i-y_j|^p$.\"\n",
    "        x_col = x.unsqueeze(-2)\n",
    "        y_lin = y.unsqueeze(-3)\n",
    "        C = torch.sum((torch.abs(x_col - y_lin)) ** p, -1)\n",
    "        return C\n",
    "\n",
    "    @staticmethod\n",
    "    def ave(u, u1, tau):\n",
    "        \"Barycenter subroutine, used by kinetic acceleration through extrapolation.\"\n",
    "        return tau * u + (1 - tau) * u1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sinkhorn = SinkhornDistance(eps=0.1, max_iter=100, reduction=None).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data.float()\n",
    "        \n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        \n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "           \n",
    "        return x\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset(set_dist)\n",
    "loader = DataLoader(dataset, batch_size = 12, shuffle = True)\n",
    "#Should ideally use larger batch size for better training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copy optimizers from cpu to gpu\n",
    "def optimizer_to(optim, device):\n",
    "    for param in optim.state.values():\n",
    "        # Not sure there are any global tensors in the state dict\n",
    "        if isinstance(param, torch.Tensor):\n",
    "            param.data = param.data.to(device)\n",
    "            if param._grad is not None:\n",
    "                param._grad.data = param._grad.data.to(device)\n",
    "        elif isinstance(param, dict):\n",
    "            for subparam in param.values():\n",
    "                if isinstance(subparam, torch.Tensor):\n",
    "                    subparam.data = subparam.data.to(device)\n",
    "                    if subparam._grad is not None:\n",
    "                        subparam._grad.data = subparam._grad.data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepSet(\n",
       "  (feature_extractor): Sequential(\n",
       "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
       "    (1): ELU(alpha=1.0, inplace=True)\n",
       "    (2): Linear(in_features=50, out_features=100, bias=True)\n",
       "    (3): ELU(alpha=1.0, inplace=True)\n",
       "    (4): Linear(in_features=100, out_features=36, bias=True)\n",
       "  )\n",
       "  (regressor): Sequential(\n",
       "    (0): Linear(in_features=36, out_features=30, bias=True)\n",
       "    (1): ELU(alpha=1.0, inplace=True)\n",
       "    (2): Linear(in_features=30, out_features=30, bias=True)\n",
       "    (3): ELU(alpha=1.0, inplace=True)\n",
       "    (4): Linear(in_features=30, out_features=10, bias=True)\n",
       "    (5): ELU(alpha=1.0, inplace=True)\n",
       "    (6): Linear(in_features=10, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DeepSet(2, 36).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "model.to(device)\n",
    "\n",
    "# checkpoint = torch.load('normal_2D_2condition1.pt')\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# model.to(device)\n",
    "# torch.cuda.empty_cache()\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "if torch.cuda.is_available() :\n",
    "#    optimizer_to(optimizer_encoder,device)\n",
    "\n",
    "# loss = checkpoint['loss']\n",
    "\n",
    "# model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wasserstein distance has the following properties: \n",
    "1) W(aX,aY) = |a|W(X,Y)\n",
    "2) W(X+x, Y+x) = W(X,Y)\n",
    "\n",
    "Only implement these properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2465], grad_fn=<DivBackward0>)\n",
      "tensor([0.3467], grad_fn=<DivBackward0>)\n",
      "tensor([0.2054], grad_fn=<DivBackward0>)\n",
      "tensor([0.2918], grad_fn=<DivBackward0>)\n",
      "tensor([0.1821], grad_fn=<DivBackward0>)\n",
      "tensor([0.2444], grad_fn=<DivBackward0>)\n",
      "tensor([0.2198], grad_fn=<DivBackward0>)\n",
      "tensor([0.2862], grad_fn=<DivBackward0>)\n",
      "tensor([0.2228], grad_fn=<DivBackward0>)\n",
      "tensor([0.2309], grad_fn=<DivBackward0>)\n",
      "tensor([0.2593], grad_fn=<DivBackward0>)\n",
      "tensor([0.2138], grad_fn=<DivBackward0>)\n",
      "tensor([0.1828], grad_fn=<DivBackward0>)\n",
      "tensor([0.2214], grad_fn=<DivBackward0>)\n",
      "tensor([0.2577], grad_fn=<DivBackward0>)\n",
      "tensor([0.2253], grad_fn=<DivBackward0>)\n",
      "tensor([0.3227], grad_fn=<DivBackward0>)\n",
      "tensor([0.2302], grad_fn=<DivBackward0>)\n",
      "tensor([0.2226], grad_fn=<DivBackward0>)\n",
      "tensor([0.2288], grad_fn=<DivBackward0>)\n",
      "tensor([0.3661], grad_fn=<DivBackward0>)\n",
      "tensor([0.2967], grad_fn=<DivBackward0>)\n",
      "tensor([0.1859], grad_fn=<DivBackward0>)\n",
      "tensor([0.2070], grad_fn=<DivBackward0>)\n",
      "tensor([0.1967], grad_fn=<DivBackward0>)\n",
      "tensor([0.2475], grad_fn=<DivBackward0>)\n",
      "tensor([0.1888], grad_fn=<DivBackward0>)\n",
      "tensor([0.2941], grad_fn=<DivBackward0>)\n",
      "tensor([0.1640], grad_fn=<DivBackward0>)\n",
      "tensor([0.2098], grad_fn=<DivBackward0>)\n",
      "tensor([0.3780], grad_fn=<DivBackward0>)\n",
      "tensor([0.4332], grad_fn=<DivBackward0>)\n",
      "tensor([0.1904], grad_fn=<DivBackward0>)\n",
      "tensor([0.2204], grad_fn=<DivBackward0>)\n",
      "tensor([0.1998], grad_fn=<DivBackward0>)\n",
      "tensor([0.2257], grad_fn=<DivBackward0>)\n",
      "tensor([0.3384], grad_fn=<DivBackward0>)\n",
      "tensor([0.2201], grad_fn=<DivBackward0>)\n",
      "tensor([0.3105], grad_fn=<DivBackward0>)\n",
      "tensor([0.2192], grad_fn=<DivBackward0>)\n",
      "tensor([0.2017], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-6bced8a0b5b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[0my_ij\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                 \u001b[0mw_ij\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msinkhorn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mya_ij\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_a\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my_a\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfs/ysm/project/dijk/as3837/conda_envs/py37_dev/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-4bb4cc50e818>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mu1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m  \u001b[0;31m# useful to check the update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1e-8\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogsumexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnu\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1e-8\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogsumexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mu1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 400\n",
    "running_loss = []\n",
    "\n",
    "for t in range(num_epochs):\n",
    "    for n_batch, batch in enumerate(loader):\n",
    "        n_data = Variable(batch.to(device), requires_grad=True)\n",
    "        a = torch.rand(1).to(device)\n",
    "        b = torch.rand(2).to(device)\n",
    "       \n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        y = model(n_data)\n",
    "        y_a = model(a*n_data)\n",
    "        y_translate = model(n_data + b)\n",
    "        \n",
    "        loss = 0\n",
    "       \n",
    "        for i in range(len(batch)):\n",
    "            for j in range(i+1,len(batch)):\n",
    "                \n",
    "                y_ij = torch.norm(y[i]-y[j], p=2)\n",
    "                w_ij = sinkhorn(n_data[i],n_data[j]) \n",
    "                \n",
    "                ya_ij = torch.norm(y_a[i]-y_a[j], p=2)\n",
    "                y_translate_ij = torch.norm(y_translate[i]-y_translate[j], p=2)\n",
    "                \n",
    "                diff_translate_ij = torch.norm(y_translate[i]-y[j], p=2)**2\n",
    "                \n",
    "    \n",
    "                loss += torch.norm(y_ij-w_ij, p=2) + (ya_ij-a*y_ij)**2 + (y_translate_ij- y_ij)**2 \n",
    "                \n",
    "                del w_ij\n",
    "        #TODO FIX THE LAST TERMS WITH PAIRWISE DISTANCES (SEE PYTORCH CODE)\n",
    "        \n",
    "        \n",
    "        loss = loss/(len(batch)*(len(batch)-1)/2)\n",
    "        \n",
    "       \n",
    "        loss.backward()\n",
    "    \n",
    "        optimizer.step()\n",
    "        if torch.cuda.is_available() :\n",
    "            torch.cuda.empty_cache() \n",
    "    \n",
    "        \n",
    "    running_loss.append(loss)\n",
    "    print(loss)\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 196+41 epochs in\n",
    "torch.save({\n",
    "           \n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss\n",
    "            \n",
    "            }, 'normal_2D_2condition1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(running_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([3.8547], grad_fn=<DivBackward0>),\n",
       " tensor([4.8018], grad_fn=<DivBackward0>),\n",
       " tensor([4.4275], grad_fn=<DivBackward0>),\n",
       " tensor([1.0452], grad_fn=<DivBackward0>),\n",
       " tensor([2.0746], grad_fn=<DivBackward0>),\n",
       " tensor([2.0337], grad_fn=<DivBackward0>),\n",
       " tensor([2.3578], grad_fn=<DivBackward0>),\n",
       " tensor([2.3841], grad_fn=<DivBackward0>),\n",
       " tensor([2.0938], grad_fn=<DivBackward0>),\n",
       " tensor([2.4092], grad_fn=<DivBackward0>),\n",
       " tensor([1.7016], grad_fn=<DivBackward0>),\n",
       " tensor([2.0407], grad_fn=<DivBackward0>),\n",
       " tensor([1.4753], grad_fn=<DivBackward0>),\n",
       " tensor([4.3986], grad_fn=<DivBackward0>),\n",
       " tensor([1.6639], grad_fn=<DivBackward0>),\n",
       " tensor([1.6180], grad_fn=<DivBackward0>),\n",
       " tensor([2.6567], grad_fn=<DivBackward0>),\n",
       " tensor([0.9153], grad_fn=<DivBackward0>),\n",
       " tensor([2.3149], grad_fn=<DivBackward0>),\n",
       " tensor([3.4223], grad_fn=<DivBackward0>),\n",
       " tensor([1.6965], grad_fn=<DivBackward0>),\n",
       " tensor([2.1763], grad_fn=<DivBackward0>),\n",
       " tensor([0.7646], grad_fn=<DivBackward0>),\n",
       " tensor([0.8246], grad_fn=<DivBackward0>),\n",
       " tensor([3.8022], grad_fn=<DivBackward0>),\n",
       " tensor([1.4288], grad_fn=<DivBackward0>),\n",
       " tensor([2.2926], grad_fn=<DivBackward0>),\n",
       " tensor([3.3592], grad_fn=<DivBackward0>),\n",
       " tensor([2.2823], grad_fn=<DivBackward0>),\n",
       " tensor([1.0660], grad_fn=<DivBackward0>),\n",
       " tensor([1.6351], grad_fn=<DivBackward0>),\n",
       " tensor([0.8052], grad_fn=<DivBackward0>),\n",
       " tensor([1.8491], grad_fn=<DivBackward0>),\n",
       " tensor([2.1351], grad_fn=<DivBackward0>),\n",
       " tensor([1.6043], grad_fn=<DivBackward0>),\n",
       " tensor([1.0153], grad_fn=<DivBackward0>),\n",
       " tensor([2.6682], grad_fn=<DivBackward0>),\n",
       " tensor([1.4098], grad_fn=<DivBackward0>),\n",
       " tensor([2.2257], grad_fn=<DivBackward0>),\n",
       " tensor([1.9868], grad_fn=<DivBackward0>),\n",
       " tensor([2.1785], grad_fn=<DivBackward0>),\n",
       " tensor([1.4375], grad_fn=<DivBackward0>),\n",
       " tensor([0.6948], grad_fn=<DivBackward0>),\n",
       " tensor([1.3695], grad_fn=<DivBackward0>),\n",
       " tensor([2.9390], grad_fn=<DivBackward0>),\n",
       " tensor([1.1498], grad_fn=<DivBackward0>),\n",
       " tensor([4.0278], grad_fn=<DivBackward0>),\n",
       " tensor([2.4214], grad_fn=<DivBackward0>),\n",
       " tensor([4.1545], grad_fn=<DivBackward0>),\n",
       " tensor([2.1357], grad_fn=<DivBackward0>),\n",
       " tensor([1.7415], grad_fn=<DivBackward0>),\n",
       " tensor([1.0856], grad_fn=<DivBackward0>)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test ground truth\n",
    "#Cov mat_1 = ID, Cov mat_2 = [[1,.5], [.5,1]], m_1 = (0,0) , m_2 = (0,1)\n",
    "#Real Wass dist^2 = ||m_1 - m_2||^2 + (4-\\sqrt(2)-\\sqrt(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.distributions.multivariate_normal.MultivariateNormal(torch.zeros(2), torch.eye(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = m.sample([250]).view(1,-1,2)\n",
    "m2 = m.sample([250]).view(1,-1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    " n = torch.distributions.multivariate_normal.MultivariateNormal(torch.tensor([0.0, 1.0]), torch.tensor([[1,.5],[.5,1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = n.sample([250]).view(1,-1,2)\n",
    "n2 = n.sample([250]).view(1,-1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0250, -1.7066]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1318, -1.6878]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1310, -1.4739]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(m1*.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0721, -2.1536]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(n1*.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3861, -2.9934]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(n1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculated distance = 1.336, scaling by .5 get distance to be .7 and moving them around got 1.323"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3756, -2.6166]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(m1+.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7009, -3.9001]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(n1+.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.3344])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sinkhorn(m1+.5, n1+.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.3344])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sinkhorn(m1,n1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3990])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sinkhorn(m1*.5, n1*.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
