{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.spatial import KDTree\n",
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd.variable import Variable\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device('cuda') if torch.cuda.is_available else torch.device('cpu')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_dist = []\n",
    "for i in range(100): \n",
    "    x = torch.rand(500,1)\n",
    "    set_dist.append(x)\n",
    "    \n",
    "for i in range(35): \n",
    "    m = torch.distributions.beta.Beta(torch.tensor([.5]), torch.tensor([.5]))\n",
    "    x = m.sample([500])\n",
    "    set_dist.append(x)\n",
    "    \n",
    "for i in range(35): \n",
    "    m = torch.distributions.beta.Beta(torch.tensor([.7]), torch.tensor([.3]))\n",
    "    x = m.sample([500])\n",
    "    set_dist.append(x)\n",
    "    \n",
    "for i in range(40): \n",
    "    m = torch.distributions.beta.Beta(torch.tensor([.2]), torch.tensor([.7]))\n",
    "    x = m.sample([500])\n",
    "    set_dist.append(x)\n",
    "    \n",
    "for i in range(50): \n",
    "    m = torch.distributions.exponential.Exponential(torch.tensor([1.5]))\n",
    "    x = m.sample([500])\n",
    "    set_dist.append(x)\n",
    "    \n",
    "for i in range(50): \n",
    "    m = torch.distributions.exponential.Exponential(torch.tensor([2.5]))\n",
    "    x = m.sample([500])\n",
    "    set_dist.append(x)\n",
    "    \n",
    "for i in range(100): \n",
    "    m = torch.distributions.gamma.Gamma(torch.tensor([1.0]), torch.tensor([1.5]))\n",
    "    x = m.sample([500])\n",
    "    set_dist.append(x)\n",
    "    \n",
    "for i in range(40): \n",
    "    m = torch.distributions.laplace.Laplace(torch.tensor([1.0]), torch.tensor([1.5]))\n",
    "    x = m.sample([500])\n",
    "    set_dist.append(x)\n",
    "    \n",
    "for i in range(59): \n",
    "    m = torch.distributions.laplace.Laplace(torch.tensor([.5]), torch.tensor([1.0]))\n",
    "    x = m.sample([500])\n",
    "    set_dist.append(x)\n",
    "    \n",
    "for i in range(100): \n",
    "    m = torch.distributions.log_normal.LogNormal(torch.tensor([0.0]), torch.tensor([0.5]))\n",
    "    x = m.sample([500])\n",
    "    set_dist.append(x)   \n",
    "\n",
    "    \n",
    "for i in range(59): \n",
    "    m = torch.distributions.normal.Normal(torch.tensor([0.0]), torch.tensor([1.0]))\n",
    "    x = m.sample([500])\n",
    "    set_dist.append(x)   \n",
    "\n",
    "for i in range(50): \n",
    "    m = torch.distributions.normal.Normal(torch.tensor([0.3]), torch.tensor([0.5]))\n",
    "    x = m.sample([500])\n",
    "    set_dist.append(x)   \n",
    "    \n",
    "    \n",
    "for i in range(100): \n",
    "    m = torch.distributions.studentT.StudentT(torch.tensor([2.0]))\n",
    "    x = m.sample([500])\n",
    "    set_dist.append(x)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_dist = torch.stack(set_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([818, 500, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Set2Set(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, act_fn=nn.Tanh, num_layers=1):\n",
    "        '''\n",
    "        Args:\n",
    "            input_dim: input dim of Set2Set. \n",
    "            hidden_dim: the dim of set representation, which is also the INPUT dimension of \n",
    "                the LSTM in Set2Set. \n",
    "                This is a concatenation of weighted sum of embedding (dim input_dim), and the LSTM\n",
    "                hidden/output (dim: self.lstm_output_dim).\n",
    "        '''\n",
    "        super(Set2Set, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        if hidden_dim <= input_dim:\n",
    "            print('ERROR: Set2Set output_dim should be larger than input_dim')\n",
    "        # the hidden is a concatenation of weighted sum of embedding and LSTM output\n",
    "        self.lstm_output_dim = hidden_dim - input_dim\n",
    "        self.lstm = nn.LSTM(hidden_dim, input_dim, num_layers=num_layers, batch_first=True)\n",
    "\n",
    "        # convert back to dim of input_dim\n",
    "       # self.pred = nn.Linear(hidden_dim, input_dim)\n",
    "        self.pred = nn.Linear(hidden_dim,4)\n",
    "        self.act = act_fn()\n",
    "\n",
    "    def forward(self, embedding):\n",
    "        '''\n",
    "        Args:\n",
    "            embedding: [batch_size x n x d] embedding matrix\n",
    "        Returns:\n",
    "            aggregated: [batch_size x d] vector representation of all embeddings\n",
    "        '''\n",
    "        batch_size = embedding.size()[0]\n",
    "        n = embedding.size()[1]\n",
    "\n",
    "        hidden = (torch.zeros(self.num_layers, batch_size, self.lstm_output_dim).cuda(),\n",
    "                  torch.zeros(self.num_layers, batch_size, self.lstm_output_dim).cuda())\n",
    "\n",
    "        q_star = torch.zeros(batch_size, 1, self.hidden_dim).cuda()\n",
    "        for i in range(n):\n",
    "            # q: batch_size x 1 x input_dim\n",
    "            q, hidden = self.lstm(q_star, hidden)\n",
    "            # e: batch_size x n x 1\n",
    "            e = embedding @ torch.transpose(q, 1, 2)\n",
    "            a = nn.Softmax(dim=1)(e)\n",
    "            r = torch.sum(a * embedding, dim=1, keepdim=True)\n",
    "            q_star = torch.cat((q, r), dim=2)\n",
    "        q_star = torch.squeeze(q_star, dim=1)\n",
    "        out = self.act(self.pred(q_star))\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepSet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, set_features):\n",
    "        super(DeepSet, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = set_features\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Linear(in_features, 50),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Linear(50, 100),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Linear(100, set_features)\n",
    "        )\n",
    "\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(set_features, 30),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Linear(30, 30),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Linear(30, 10),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Linear(10, 2),\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, input):\n",
    "        x = input\n",
    "        x = self.feature_extractor(x)\n",
    "        x = x.sum(dim=1)\n",
    "        x = self.regressor(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\" Set Encoder \n",
    "    \"\"\"\n",
    "    def __init__(self, dim_Q, dim_K, dim_V, d_model, num_heads, ln=False, skip=True):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.dim_V = dim_V\n",
    "        self.num_heads = num_heads\n",
    "        self.skip = skip\n",
    "       # self.s_max = s_max\n",
    "        #Maximum set size\n",
    "        self.d_model = d_model\n",
    "        self.fc_q = nn.Linear(dim_Q, d_model)\n",
    "        self.fc_k = nn.Linear(dim_K, d_model)\n",
    "        self.fc_v = nn.Linear(dim_K, d_model)\n",
    "        if ln:\n",
    "            self.ln0 = nn.LayerNorm(d_model)\n",
    "            self.ln1 = nn.LayerNorm(d_model)\n",
    "        #This is the classic pointwise feedforward in \"Attention is All you need\"\n",
    "        self.ff = nn.Sequential(\n",
    "        nn.Linear(d_model, 4 * d_model),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(4 * d_model, d_model))\n",
    "        # I have experimented with just a smaller version of this \n",
    "       # self.fc_o = nn.Linear(d_model,d_model)\n",
    "        \n",
    "     #   self.fc_rep = nn.Linear(s_max, 1)\n",
    "#number of heads must divide output size = d_model\n",
    "        \n",
    "\n",
    "    def forward(self, Q, K):\n",
    "        Q = self.fc_q(Q)\n",
    "      \n",
    "        K, V = self.fc_k(K), self.fc_v(K)\n",
    "\n",
    "        dim_split = self.d_model // self.num_heads\n",
    "        Q_ = torch.cat(Q.split(dim_split, 2), 0)\n",
    "        K_ = torch.cat(K.split(dim_split, 2), 0)\n",
    "        V_ = torch.cat(V.split(dim_split, 2), 0)\n",
    "  \n",
    "\n",
    "        A = torch.softmax(Q_.bmm(K_.transpose(-2,-1))/math.sqrt(self.d_model), dim=-1)\n",
    "        A_1 = A.bmm(V_)\n",
    "        \n",
    " \n",
    "        O = torch.cat((A_1).split(Q.size(0), 0), 2)\n",
    "       \n",
    "        O = torch.cat((Q_ + A_1).split(Q.size(0), 0), 2) if getattr(self, 'skip', True) else \\\n",
    "             torch.cat((A_1).split(Q.size(0), 0), 2)\n",
    "        O = O if getattr(self, 'ln0', None) is None else self.ln0(O)\n",
    "       # O = O + F.relu(self.fc_o(O)) if getattr(self, 'skip', None) is None else F.relu(self.fc_o(O))\n",
    "        # For the classic transformers paper it is \n",
    "        O = O + self.ff(O)\n",
    "        O = O if getattr(self, 'ln1', None) is None else self.ln1(O)\n",
    "        O = torch.mean(O,dim=1)\n",
    "#         O = pad_sequence(O, batch_first=True, padding_value=0)\n",
    "#         O = O.transpose(-2,-1)\n",
    "#         O = F.pad(O, (0, self.s_max- O.shape[-1]), 'constant', 0)\n",
    "      #  O = self.fc_rep(O)\n",
    "       # O = self.fc_rep(O.transpose(-2,-1))\n",
    "      #  O = O.squeeze()\n",
    "\n",
    "        return O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, dim_in=18, dim_out=8, num_heads=2, ln=True, skip=True):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.Encoder = Encoder(dim_in, dim_in, dim_in, dim_out, num_heads, ln=ln, skip=skip)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.Encoder(X, X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-15\n",
    "\"\"\"Approximating KL divergences between two probability densities using samples. \n",
    "    It is buggy. Use at your own peril\n",
    "\"\"\"\n",
    "\n",
    "def knn_distance(point, sample, k):\n",
    "    \"\"\" Euclidean distance from `point` to it's `k`-Nearest\n",
    "    Neighbour in `sample` \"\"\"\n",
    "    norms = np.linalg.norm(sample-point, axis=1)\n",
    "    return np.sort(norms)[k]\n",
    "\n",
    "\n",
    "def verify_sample_shapes(s1, s2, k):\n",
    "    # Expects [N, D]\n",
    "    assert(len(s1.shape) == len(s2.shape) == 2)\n",
    "    # Check dimensionality of sample is identical\n",
    "    assert(s1.shape[1] == s2.shape[1])\n",
    "\n",
    "\n",
    "def naive_estimator(s1, s2, k=1):\n",
    "    \"\"\" KL-Divergence estimator using brute-force (numpy) k-NN\n",
    "        s1: (N_1,D) Sample drawn from distribution P\n",
    "        s2: (N_2,D) Sample drawn from distribution Q\n",
    "        k: Number of neighbours considered (default 1)\n",
    "        return: estimated D(P|Q)\n",
    "    \"\"\"\n",
    "    verify_sample_shapes(s1, s2, k)\n",
    "\n",
    "    n, m = len(s1), len(s2)\n",
    "    D = np.log(m / (n - 1))\n",
    "    d = float(s1.shape[1])\n",
    "\n",
    "    for p1 in s1:\n",
    "        nu = knn_distance(p1, s2, k-1)  # -1 because 'p1' is not in 's2'\n",
    "        rho = knn_distance(p1, s1, k)\n",
    "        D += (d/n)*np.log((nu/rho)+eps)\n",
    "    return D\n",
    "\n",
    "\n",
    "def scipy_estimator(s1, s2, k=1):\n",
    "    \"\"\" KL-Divergence estimator using scipy's KDTree\n",
    "        s1: (N_1,D) Sample drawn from distribution P\n",
    "        s2: (N_2,D) Sample drawn from distribution Q\n",
    "        k: Number of neighbours considered (default 1)\n",
    "        return: estimated D(P|Q)\n",
    "    \"\"\"\n",
    "    verify_sample_shapes(s1, s2, k)\n",
    "\n",
    "    n, m = len(s1), len(s2)\n",
    "    d = float(s1.shape[1])\n",
    "    D = np.log(m / (n - 1))\n",
    "\n",
    "    nu_d,  nu_i   = KDTree(s2).query(s1, k)\n",
    "    rho_d, rhio_i = KDTree(s1).query(s1, k+1)\n",
    "\n",
    "    # KTree.query returns different shape in k==1 vs k > 1\n",
    "    if k > 1:\n",
    "        D += (d/n)*np.sum(np.log(nu_d[::, -1]/rho_d[::, -1]))\n",
    "    else:\n",
    "        D += (d/n)*np.sum(np.log(nu_d/rho_d[::, -1]))\n",
    "\n",
    "    return D\n",
    "\n",
    "\n",
    "def skl_estimator(s1, s2, k=1):\n",
    "    \"\"\" KL-Divergence estimator using scikit-learn's NearestNeighbours\n",
    "        s1: (N_1,D) Sample drawn from distribution P\n",
    "        s2: (N_2,D) Sample drawn from distribution Q\n",
    "        k: Number of neighbours considered (default 1)\n",
    "        return: estimated D(P|Q)\n",
    "    \"\"\"\n",
    "    verify_sample_shapes(s1, s2, k)\n",
    "\n",
    "    n, m = len(s1), len(s2)\n",
    "    d = float(s1.shape[1])\n",
    "    D = np.log(m / (n - 1))\n",
    "\n",
    "    s1_neighbourhood = NearestNeighbors(k+1, 10).fit(s1)\n",
    "    s2_neighbourhood = NearestNeighbors(k, 10).fit(s2)\n",
    "\n",
    "    for p1 in s1:\n",
    "        s1_distances, indices = s1_neighbourhood.kneighbors([p1], k+1)\n",
    "        s2_distances, indices = s2_neighbourhood.kneighbors([p1], k)\n",
    "        rho = s1_distances[0][-1]\n",
    "        nu = s2_distances[0][-1]\n",
    "        D += (d/n)*np.log(nu/rho)\n",
    "    return D\n",
    "\n",
    "\n",
    "# List of all estimators\n",
    "Estimators = [naive_estimator, scipy_estimator, skl_estimator]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinkhornDistance(nn.Module):\n",
    "    r\"\"\"\n",
    "    Given two empirical measures each with :math:`P_1` locations\n",
    "    :math:`x\\in\\mathbb{R}^{D_1}` and :math:`P_2` locations :math:`y\\in\\mathbb{R}^{D_2}`,\n",
    "    outputs an approximation of the regularized OT cost for point clouds.\n",
    "    Args:\n",
    "        eps (float): regularization coefficient\n",
    "        max_iter (int): maximum number of Sinkhorn iterations\n",
    "        reduction (string, optional): Specifies the reduction to apply to the output:\n",
    "            'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n",
    "            'mean': the sum of the output will be divided by the number of\n",
    "            elements in the output, 'sum': the output will be summed. Default: 'none'\n",
    "    Shape:\n",
    "        - Input: :math:`(N, P_1, D_1)`, :math:`(N, P_2, D_2)`\n",
    "        - Output: :math:`(N)` or :math:`()`, depending on `reduction`\n",
    "    \"\"\"\n",
    "    def __init__(self, eps, max_iter, reduction='none'):\n",
    "        super(SinkhornDistance, self).__init__()\n",
    "        self.eps = eps\n",
    "        self.max_iter = max_iter\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        # The Sinkhorn algorithm takes as input three variables :\n",
    "        C = self._cost_matrix(x, y)  # Wasserstein cost function\n",
    "        x_points = x.shape[-2]\n",
    "        y_points = y.shape[-2]\n",
    "        if x.dim() == 2:\n",
    "            batch_size = 1\n",
    "        else:\n",
    "            batch_size = x.shape[0]\n",
    "\n",
    "        # both marginals are fixed with equal weights\n",
    "        mu = torch.empty(batch_size, x_points, dtype=torch.float,\n",
    "                         requires_grad=False).fill_(1.0 / x_points).to(device).squeeze()\n",
    "        nu = torch.empty(batch_size, y_points, dtype=torch.float,\n",
    "                         requires_grad=False).fill_(1.0 / y_points).to(device).squeeze()\n",
    "\n",
    "        u = torch.zeros_like(mu).to(device)\n",
    "        v = torch.zeros_like(nu).to(device)\n",
    "        # To check if algorithm terminates because of threshold\n",
    "        # or max iterations reached\n",
    "        actual_nits = 0\n",
    "        # Stopping criterion\n",
    "        thresh = 1e-1\n",
    "\n",
    "        # Sinkhorn iterations\n",
    "        for i in range(self.max_iter):\n",
    "            u1 = u  # useful to check the update\n",
    "            u = self.eps * (torch.log(mu+1e-8) - torch.logsumexp(self.M(C, u, v), dim=-1)) + u\n",
    "            v = self.eps * (torch.log(nu+1e-8) - torch.logsumexp(self.M(C, u, v).transpose(-2, -1), dim=-1)) + v\n",
    "            err = (u - u1).abs().sum(-1).mean()\n",
    "\n",
    "            actual_nits += 1\n",
    "            if err.item() < thresh:\n",
    "                break\n",
    "\n",
    "        U, V = u, v\n",
    "        # Transport plan pi = diag(a)*K*diag(b)\n",
    "        pi = torch.exp(self.M(C, U, V))\n",
    "        # Sinkhorn distance\n",
    "        cost = torch.sum(pi * C, dim=(-2, -1))\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            cost = cost.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            cost = cost.sum()\n",
    "\n",
    "      #  return cost, pi, C\n",
    "        return cost\n",
    "\n",
    "    def M(self, C, u, v):\n",
    "        \"Modified cost for logarithmic updates\"\n",
    "        \"$M_{ij} = (-c_{ij} + u_i + v_j) / \\epsilon$\"\n",
    "        return (-C + u.unsqueeze(-1) + v.unsqueeze(-2)) / self.eps\n",
    "\n",
    "    @staticmethod\n",
    "    def _cost_matrix(x, y, p=2):\n",
    "        \"Returns the matrix of $|x_i-y_j|^p$.\"\n",
    "        x_col = x.unsqueeze(-2)\n",
    "        y_lin = y.unsqueeze(-3)\n",
    "        C = torch.sum((torch.abs(x_col - y_lin)) ** p, -1)\n",
    "        return C\n",
    "\n",
    "    @staticmethod\n",
    "    def ave(u, u1, tau):\n",
    "        \"Barycenter subroutine, used by kinetic acceleration through extrapolation.\"\n",
    "        return tau * u + (1 - tau) * u1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sinkhorn = SinkhornDistance(eps=0.1, max_iter=100, reduction=None).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data.float()\n",
    "        \n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        \n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "           \n",
    "        return x\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset(set_dist)\n",
    "loader = DataLoader(dataset, batch_size = 12, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepSet(\n",
       "  (feature_extractor): Sequential(\n",
       "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
       "    (1): ELU(alpha=1.0, inplace=True)\n",
       "    (2): Linear(in_features=50, out_features=100, bias=True)\n",
       "    (3): ELU(alpha=1.0, inplace=True)\n",
       "    (4): Linear(in_features=100, out_features=36, bias=True)\n",
       "  )\n",
       "  (regressor): Sequential(\n",
       "    (0): Linear(in_features=36, out_features=30, bias=True)\n",
       "    (1): ELU(alpha=1.0, inplace=True)\n",
       "    (2): Linear(in_features=30, out_features=30, bias=True)\n",
       "    (3): ELU(alpha=1.0, inplace=True)\n",
       "    (4): Linear(in_features=30, out_features=10, bias=True)\n",
       "    (5): ELU(alpha=1.0, inplace=True)\n",
       "    (6): Linear(in_features=10, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DeepSet(1, 36).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "checkpoint = torch.load('deepset_dist_2conditions_5.pt')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "loss = checkpoint['loss']\n",
    "\n",
    "\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wasserstein distance has the following properties: \n",
    "1) W(aX,aY) = |a|W(X,Y)\n",
    "2) W(X+x, Y+x) = W(X,Y)\n",
    "3) ...\n",
    "Here we remove the 3rd condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.2000], grad_fn=<DivBackward0>)\n",
      "tensor([0.0772], grad_fn=<DivBackward0>)\n",
      "tensor([0.1091], grad_fn=<DivBackward0>)\n",
      "tensor([0.2511], grad_fn=<DivBackward0>)\n",
      "tensor([0.3571], grad_fn=<DivBackward0>)\n",
      "tensor([0.2765], grad_fn=<DivBackward0>)\n",
      "tensor([8.8389], grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-abd0a661fbe7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0my_ij\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                 \u001b[0mw_ij\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msinkhorn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0mya_ij\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_a\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my_a\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfs/ysm/project/dijk/as3837/conda_envs/py37_dev/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-4bb4cc50e818>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mu1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu\u001b[0m  \u001b[0;31m# useful to check the update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1e-8\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogsumexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnu\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1e-8\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogsumexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mu1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 500\n",
    "running_loss = []\n",
    "for t in range(num_epochs):\n",
    "    for n_batch, batch in enumerate(loader):\n",
    "        n_data = Variable(batch.to(device), requires_grad=True)\n",
    "        a = torch.rand(1).to(device)\n",
    "        b = torch.rand(1).to(device)\n",
    "       \n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        y = model(n_data)\n",
    "        y_a = model(a*n_data)\n",
    "        y_translate = model(n_data + b)\n",
    "        \n",
    "        loss = 0\n",
    "       \n",
    "        for i in range(len(batch)):\n",
    "            for j in range(i+1,len(batch)):\n",
    "                \n",
    "                y_ij = torch.norm(y[i]-y[j], p=2)\n",
    "                w_ij = sinkhorn(n_data[i],n_data[j]) \n",
    "                \n",
    "                ya_ij = torch.norm(y_a[i]-y_a[j], p=2)\n",
    "                y_translate_ij = torch.norm(y_translate[i]-y_translate[j], p=2)\n",
    "                \n",
    "                diff_translate_ij = torch.norm(y_translate[i]-y[j], p=2)**2\n",
    "                \n",
    "    \n",
    "                loss += torch.norm(y_ij-w_ij, p=2) + (ya_ij-a*y_ij)**2 + (y_translate_ij- y_ij)**2\n",
    "                \n",
    "                del w_ij\n",
    "        #Trying without the last condition. That condition seems buggy\n",
    "        \n",
    "        \n",
    "        loss = loss/(len(batch)*(len(batch)-1)/2)\n",
    "       \n",
    "        loss.backward()\n",
    "       \n",
    "        optimizer.step()\n",
    "    \n",
    "        \n",
    "    running_loss.append(loss)\n",
    "    print(loss)\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First save is at 31 epochs, 2nd save after 31 epochs, 3rd save is after 41 epochs, \n",
    "#4th save is after 16 epochs, 5th save is after 35+28+36 +27+27+7epochs\n",
    "torch.save(model.state_dict(),'deepset_dist_2conditions_5.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First save is at 31 epochs \n",
    "torch.save({\n",
    "    \n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss\n",
    "            \n",
    "            }, 'deepset_dist_2conditions_5.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(running_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0.1440], grad_fn=<DivBackward0>),\n",
       " tensor([0.3766], grad_fn=<DivBackward0>),\n",
       " tensor([0.5662], grad_fn=<DivBackward0>),\n",
       " tensor([0.2024], grad_fn=<DivBackward0>),\n",
       " tensor([0.0106], grad_fn=<DivBackward0>),\n",
       " tensor([1.2433], grad_fn=<DivBackward0>),\n",
       " tensor([3.4340], grad_fn=<DivBackward0>),\n",
       " tensor([0.0118], grad_fn=<DivBackward0>),\n",
       " tensor([0.0117], grad_fn=<DivBackward0>),\n",
       " tensor([0.0505], grad_fn=<DivBackward0>),\n",
       " tensor([0.1220], grad_fn=<DivBackward0>),\n",
       " tensor([0.0999], grad_fn=<DivBackward0>),\n",
       " tensor([0.1208], grad_fn=<DivBackward0>),\n",
       " tensor([0.3677], grad_fn=<DivBackward0>),\n",
       " tensor([0.1946], grad_fn=<DivBackward0>),\n",
       " tensor([0.0537], grad_fn=<DivBackward0>),\n",
       " tensor([0.0784], grad_fn=<DivBackward0>),\n",
       " tensor([1.0553], grad_fn=<DivBackward0>),\n",
       " tensor([0.1567], grad_fn=<DivBackward0>),\n",
       " tensor([0.1373], grad_fn=<DivBackward0>),\n",
       " tensor([0.3823], grad_fn=<DivBackward0>),\n",
       " tensor([0.0995], grad_fn=<DivBackward0>),\n",
       " tensor([0.3317], grad_fn=<DivBackward0>),\n",
       " tensor([0.0396], grad_fn=<DivBackward0>),\n",
       " tensor([0.6157], grad_fn=<DivBackward0>)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.rand(1,500,1)\n",
    "y = torch.rand(1,500,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[339.1930,  32.6299]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[333.4408,  69.7056]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.distributions.normal.Normal(torch.tensor([0.0]), torch.tensor([1.0]))\n",
    "m1 = m.sample([500]).view(1,-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[333.1962,  70.6661]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = m.sample([500]).view(1,-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[333.1590,  70.7157]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = torch.distributions.normal.Normal(torch.tensor([.05]), torch.tensor([1.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = n.sample([500]).view(1,-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[333.1236,  70.5438]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(n1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "n2 = n.sample([500]).view(1,-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[333.1834,  70.6742]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(n2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = torch.distributions.normal.Normal(torch.tensor([.5]), torch.tensor([.75]))\n",
    "N1 = N.sample([500]).view(1,-1,1)\n",
    "N2 = N.sample([500]).view(1,-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[333.1003,  69.9509]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(N1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[333.0479,  69.9547]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(N2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.ones(500).view(1,-1,1)\n",
    "B = torch.zeros(500).view(1,-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[332.7984,  69.3419]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[333.6949,  70.2485]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9999])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sinkhorn(A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = torch.distributions.bernoulli.Bernoulli(torch.tensor([.3]))\n",
    "D = torch.distributions.bernoulli.Bernoulli(torch.tensor([.5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "C1 = C.sample([500]).view(1,-1,1)\n",
    "D1 = D.sample([500]).view(1,-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[333.4170,  69.9675]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(C1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[333.2431,  69.7915]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(D1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1937])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sinkhorn(C1,D1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
