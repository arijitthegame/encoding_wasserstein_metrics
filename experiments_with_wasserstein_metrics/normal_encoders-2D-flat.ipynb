{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.spatial import KDTree\n",
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd.variable import Variable\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device('cuda') if torch.cuda.is_available else torch.device('cpu')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_dist = []\n",
    "\n",
    "\n",
    "for i in range(50): \n",
    "    m = torch.distributions.multivariate_normal.MultivariateNormal(torch.zeros(2), torch.eye(2))\n",
    "    x = m.sample([250])\n",
    "    set_dist.append(x) \n",
    "    \n",
    "for i in range(50): \n",
    "    m = torch.distributions.multivariate_normal.MultivariateNormal(torch.tensor([0.0, 1.0]), torch.tensor([[1,.5],[.5,1]]))\n",
    "    x = m.sample([250])\n",
    "    set_dist.append(x) \n",
    "    \n",
    "for i in range(50): \n",
    "    m = torch.distributions.multivariate_normal.MultivariateNormal(torch.ones(2), covariance_matrix=torch.tensor([[.7,.1],[.1,1]]))\n",
    "    x = m.sample([250])\n",
    "    set_dist.append(x) \n",
    "    \n",
    "for i in range(50): \n",
    "    m = torch.distributions.multivariate_normal.MultivariateNormal(torch.tensor([1.0, 0.0]), torch.tensor([[.2, -.1], [-.1, 1]]))\n",
    "    x = m.sample([250])\n",
    "    set_dist.append(x) \n",
    "    \n",
    "for i in range(50): \n",
    "    m = torch.distributions.multivariate_normal.MultivariateNormal(torch.tensor([.5, .5]), torch.tensor([[.8,.4],[.4,1]]))\n",
    "    x = m.sample([250])\n",
    "    set_dist.append(x) \n",
    "    \n",
    "for i in range(50): \n",
    "    m = torch.distributions.multivariate_normal.MultivariateNormal(torch.tensor([-.25, -.5]), torch.eye(2)*.5)\n",
    "    x = m.sample([250])\n",
    "    set_dist.append(x) \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_dist = torch.stack(set_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300, 250, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Set2Set(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, act_fn=nn.Tanh, num_layers=1):\n",
    "        '''\n",
    "        Args:\n",
    "            input_dim: input dim of Set2Set. \n",
    "            hidden_dim: the dim of set representation, which is also the INPUT dimension of \n",
    "                the LSTM in Set2Set. \n",
    "                This is a concatenation of weighted sum of embedding (dim input_dim), and the LSTM\n",
    "                hidden/output (dim: self.lstm_output_dim).\n",
    "        '''\n",
    "        super(Set2Set, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        if hidden_dim <= input_dim:\n",
    "            print('ERROR: Set2Set output_dim should be larger than input_dim')\n",
    "        # the hidden is a concatenation of weighted sum of embedding and LSTM output\n",
    "        self.lstm_output_dim = hidden_dim - input_dim\n",
    "        self.lstm = nn.LSTM(hidden_dim, input_dim, num_layers=num_layers, batch_first=True)\n",
    "\n",
    "        # convert back to dim of input_dim\n",
    "       # self.pred = nn.Linear(hidden_dim, input_dim)\n",
    "        self.pred = nn.Linear(hidden_dim,4)\n",
    "        self.act = act_fn()\n",
    "\n",
    "    def forward(self, embedding):\n",
    "        '''\n",
    "        Args:\n",
    "            embedding: [batch_size x n x d] embedding matrix\n",
    "        Returns:\n",
    "            aggregated: [batch_size x d] vector representation of all embeddings\n",
    "        '''\n",
    "        batch_size = embedding.size()[0]\n",
    "        n = embedding.size()[1]\n",
    "\n",
    "        hidden = (torch.zeros(self.num_layers, batch_size, self.lstm_output_dim).cuda(),\n",
    "                  torch.zeros(self.num_layers, batch_size, self.lstm_output_dim).cuda())\n",
    "\n",
    "        q_star = torch.zeros(batch_size, 1, self.hidden_dim).cuda()\n",
    "        for i in range(n):\n",
    "            # q: batch_size x 1 x input_dim\n",
    "            q, hidden = self.lstm(q_star, hidden)\n",
    "            # e: batch_size x n x 1\n",
    "            e = embedding @ torch.transpose(q, 1, 2)\n",
    "            a = nn.Softmax(dim=1)(e)\n",
    "            r = torch.sum(a * embedding, dim=1, keepdim=True)\n",
    "            q_star = torch.cat((q, r), dim=2)\n",
    "        q_star = torch.squeeze(q_star, dim=1)\n",
    "        out = self.act(self.pred(q_star))\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepSet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, set_features):\n",
    "        super(DeepSet, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = set_features\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Linear(in_features, 50),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Linear(50, 100),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Linear(100, set_features)\n",
    "        )\n",
    "\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(set_features, 30),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Linear(30, 30),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Linear(30, 10),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Linear(10, 2),\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, input):\n",
    "        x = input\n",
    "        x = self.feature_extractor(x)\n",
    "        x = x.sum(dim=1)\n",
    "        x = self.regressor(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\" Set Encoder \n",
    "    \"\"\"\n",
    "    def __init__(self, dim_Q, dim_K, dim_V, d_model, num_heads, ln=False, skip=True):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.dim_V = dim_V\n",
    "        self.num_heads = num_heads\n",
    "        self.skip = skip\n",
    "       # self.s_max = s_max\n",
    "        #Maximum set size\n",
    "        self.d_model = d_model\n",
    "        self.fc_q = nn.Linear(dim_Q, d_model)\n",
    "        self.fc_k = nn.Linear(dim_K, d_model)\n",
    "        self.fc_v = nn.Linear(dim_K, d_model)\n",
    "        if ln:\n",
    "            self.ln0 = nn.LayerNorm(d_model)\n",
    "            self.ln1 = nn.LayerNorm(d_model)\n",
    "        #This is the classic pointwise feedforward in \"Attention is All you need\"\n",
    "        self.ff = nn.Sequential(\n",
    "        nn.Linear(d_model, 4 * d_model),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(4 * d_model, d_model))\n",
    "        # I have experimented with just a smaller version of this \n",
    "       # self.fc_o = nn.Linear(d_model,d_model)\n",
    "        \n",
    "     #   self.fc_rep = nn.Linear(s_max, 1)\n",
    "#number of heads must divide output size = d_model\n",
    "        \n",
    "\n",
    "    def forward(self, Q, K):\n",
    "        Q = self.fc_q(Q)\n",
    "      \n",
    "        K, V = self.fc_k(K), self.fc_v(K)\n",
    "\n",
    "        dim_split = self.d_model // self.num_heads\n",
    "        Q_ = torch.cat(Q.split(dim_split, 2), 0)\n",
    "        K_ = torch.cat(K.split(dim_split, 2), 0)\n",
    "        V_ = torch.cat(V.split(dim_split, 2), 0)\n",
    "  \n",
    "\n",
    "        A = torch.softmax(Q_.bmm(K_.transpose(-2,-1))/math.sqrt(self.d_model), dim=-1)\n",
    "        A_1 = A.bmm(V_)\n",
    "        \n",
    " \n",
    "        O = torch.cat((A_1).split(Q.size(0), 0), 2)\n",
    "       \n",
    "        O = torch.cat((Q_ + A_1).split(Q.size(0), 0), 2) if getattr(self, 'skip', True) else \\\n",
    "             torch.cat((A_1).split(Q.size(0), 0), 2)\n",
    "        O = O if getattr(self, 'ln0', None) is None else self.ln0(O)\n",
    "       # O = O + F.relu(self.fc_o(O)) if getattr(self, 'skip', None) is None else F.relu(self.fc_o(O))\n",
    "        # For the classic transformers paper it is \n",
    "        O = O + self.ff(O)\n",
    "        O = O if getattr(self, 'ln1', None) is None else self.ln1(O)\n",
    "        O = torch.mean(O,dim=1)\n",
    "#         O = pad_sequence(O, batch_first=True, padding_value=0)\n",
    "#         O = O.transpose(-2,-1)\n",
    "#         O = F.pad(O, (0, self.s_max- O.shape[-1]), 'constant', 0)\n",
    "      #  O = self.fc_rep(O)\n",
    "       # O = self.fc_rep(O.transpose(-2,-1))\n",
    "      #  O = O.squeeze()\n",
    "\n",
    "        return O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, dim_in=18, dim_out=8, num_heads=2, ln=True, skip=True):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.Encoder = Encoder(dim_in, dim_in, dim_in, dim_out, num_heads, ln=ln, skip=skip)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.Encoder(X, X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-15\n",
    "\"\"\"Approximating KL divergences between two probability densities using samples. \n",
    "    It is buggy. Use at your own peril\n",
    "\"\"\"\n",
    "\n",
    "def knn_distance(point, sample, k):\n",
    "    \"\"\" Euclidean distance from `point` to it's `k`-Nearest\n",
    "    Neighbour in `sample` \"\"\"\n",
    "    norms = np.linalg.norm(sample-point, axis=1)\n",
    "    return np.sort(norms)[k]\n",
    "\n",
    "\n",
    "def verify_sample_shapes(s1, s2, k):\n",
    "    # Expects [N, D]\n",
    "    assert(len(s1.shape) == len(s2.shape) == 2)\n",
    "    # Check dimensionality of sample is identical\n",
    "    assert(s1.shape[1] == s2.shape[1])\n",
    "\n",
    "\n",
    "def naive_estimator(s1, s2, k=1):\n",
    "    \"\"\" KL-Divergence estimator using brute-force (numpy) k-NN\n",
    "        s1: (N_1,D) Sample drawn from distribution P\n",
    "        s2: (N_2,D) Sample drawn from distribution Q\n",
    "        k: Number of neighbours considered (default 1)\n",
    "        return: estimated D(P|Q)\n",
    "    \"\"\"\n",
    "    verify_sample_shapes(s1, s2, k)\n",
    "\n",
    "    n, m = len(s1), len(s2)\n",
    "    D = np.log(m / (n - 1))\n",
    "    d = float(s1.shape[1])\n",
    "\n",
    "    for p1 in s1:\n",
    "        nu = knn_distance(p1, s2, k-1)  # -1 because 'p1' is not in 's2'\n",
    "        rho = knn_distance(p1, s1, k)\n",
    "        D += (d/n)*np.log((nu/rho)+eps)\n",
    "    return D\n",
    "\n",
    "\n",
    "def scipy_estimator(s1, s2, k=1):\n",
    "    \"\"\" KL-Divergence estimator using scipy's KDTree\n",
    "        s1: (N_1,D) Sample drawn from distribution P\n",
    "        s2: (N_2,D) Sample drawn from distribution Q\n",
    "        k: Number of neighbours considered (default 1)\n",
    "        return: estimated D(P|Q)\n",
    "    \"\"\"\n",
    "    verify_sample_shapes(s1, s2, k)\n",
    "\n",
    "    n, m = len(s1), len(s2)\n",
    "    d = float(s1.shape[1])\n",
    "    D = np.log(m / (n - 1))\n",
    "\n",
    "    nu_d,  nu_i   = KDTree(s2).query(s1, k)\n",
    "    rho_d, rhio_i = KDTree(s1).query(s1, k+1)\n",
    "\n",
    "    # KTree.query returns different shape in k==1 vs k > 1\n",
    "    if k > 1:\n",
    "        D += (d/n)*np.sum(np.log(nu_d[::, -1]/rho_d[::, -1]))\n",
    "    else:\n",
    "        D += (d/n)*np.sum(np.log(nu_d/rho_d[::, -1]))\n",
    "\n",
    "    return D\n",
    "\n",
    "\n",
    "def skl_estimator(s1, s2, k=1):\n",
    "    \"\"\" KL-Divergence estimator using scikit-learn's NearestNeighbours\n",
    "        s1: (N_1,D) Sample drawn from distribution P\n",
    "        s2: (N_2,D) Sample drawn from distribution Q\n",
    "        k: Number of neighbours considered (default 1)\n",
    "        return: estimated D(P|Q)\n",
    "    \"\"\"\n",
    "    verify_sample_shapes(s1, s2, k)\n",
    "\n",
    "    n, m = len(s1), len(s2)\n",
    "    d = float(s1.shape[1])\n",
    "    D = np.log(m / (n - 1))\n",
    "\n",
    "    s1_neighbourhood = NearestNeighbors(k+1, 10).fit(s1)\n",
    "    s2_neighbourhood = NearestNeighbors(k, 10).fit(s2)\n",
    "\n",
    "    for p1 in s1:\n",
    "        s1_distances, indices = s1_neighbourhood.kneighbors([p1], k+1)\n",
    "        s2_distances, indices = s2_neighbourhood.kneighbors([p1], k)\n",
    "        rho = s1_distances[0][-1]\n",
    "        nu = s2_distances[0][-1]\n",
    "        D += (d/n)*np.log(nu/rho)\n",
    "    return D\n",
    "\n",
    "\n",
    "# List of all estimators\n",
    "Estimators = [naive_estimator, scipy_estimator, skl_estimator]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinkhornDistance(nn.Module):\n",
    "    r\"\"\"\n",
    "    Given two empirical measures each with :math:`P_1` locations\n",
    "    :math:`x\\in\\mathbb{R}^{D_1}` and :math:`P_2` locations :math:`y\\in\\mathbb{R}^{D_2}`,\n",
    "    outputs an approximation of the regularized OT cost for point clouds.\n",
    "    Args:\n",
    "        eps (float): regularization coefficient\n",
    "        max_iter (int): maximum number of Sinkhorn iterations\n",
    "        reduction (string, optional): Specifies the reduction to apply to the output:\n",
    "            'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n",
    "            'mean': the sum of the output will be divided by the number of\n",
    "            elements in the output, 'sum': the output will be summed. Default: 'none'\n",
    "    Shape:\n",
    "        - Input: :math:`(N, P_1, D_1)`, :math:`(N, P_2, D_2)`\n",
    "        - Output: :math:`(N)` or :math:`()`, depending on `reduction`\n",
    "    \"\"\"\n",
    "    def __init__(self, eps, max_iter, reduction='none'):\n",
    "        super(SinkhornDistance, self).__init__()\n",
    "        self.eps = eps\n",
    "        self.max_iter = max_iter\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        # The Sinkhorn algorithm takes as input three variables :\n",
    "        C = self._cost_matrix(x, y)  # Wasserstein cost function\n",
    "        x_points = x.shape[-2]\n",
    "        y_points = y.shape[-2]\n",
    "        if x.dim() == 2:\n",
    "            batch_size = 1\n",
    "        else:\n",
    "            batch_size = x.shape[0]\n",
    "\n",
    "        # both marginals are fixed with equal weights\n",
    "        mu = torch.empty(batch_size, x_points, dtype=torch.float,\n",
    "                         requires_grad=False).fill_(1.0 / x_points).to(device).squeeze()\n",
    "        nu = torch.empty(batch_size, y_points, dtype=torch.float,\n",
    "                         requires_grad=False).fill_(1.0 / y_points).to(device).squeeze()\n",
    "\n",
    "        u = torch.zeros_like(mu).to(device)\n",
    "        v = torch.zeros_like(nu).to(device)\n",
    "        # To check if algorithm terminates because of threshold\n",
    "        # or max iterations reached\n",
    "        actual_nits = 0\n",
    "        # Stopping criterion\n",
    "        thresh = 1e-1\n",
    "\n",
    "        # Sinkhorn iterations\n",
    "        for i in range(self.max_iter):\n",
    "            u1 = u  # useful to check the update\n",
    "            u = self.eps * (torch.log(mu+1e-8) - torch.logsumexp(self.M(C, u, v), dim=-1)) + u\n",
    "            v = self.eps * (torch.log(nu+1e-8) - torch.logsumexp(self.M(C, u, v).transpose(-2, -1), dim=-1)) + v\n",
    "            err = (u - u1).abs().sum(-1).mean()\n",
    "\n",
    "            actual_nits += 1\n",
    "            if err.item() < thresh:\n",
    "                break\n",
    "\n",
    "        U, V = u, v\n",
    "        # Transport plan pi = diag(a)*K*diag(b)\n",
    "        pi = torch.exp(self.M(C, U, V))\n",
    "        # Sinkhorn distance\n",
    "        cost = torch.sum(pi * C, dim=(-2, -1))\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            cost = cost.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            cost = cost.sum()\n",
    "\n",
    "      #  return cost, pi, C\n",
    "        return cost\n",
    "\n",
    "    def M(self, C, u, v):\n",
    "        \"Modified cost for logarithmic updates\"\n",
    "        \"$M_{ij} = (-c_{ij} + u_i + v_j) / \\epsilon$\"\n",
    "        return (-C + u.unsqueeze(-1) + v.unsqueeze(-2)) / self.eps\n",
    "\n",
    "    @staticmethod\n",
    "    def _cost_matrix(x, y, p=1):\n",
    "        \"Returns the matrix of $|x_i-y_j|^p$.\"\n",
    "        x_col = x.unsqueeze(-2)\n",
    "        y_lin = y.unsqueeze(-3)\n",
    "        C = torch.sum((torch.abs(x_col - y_lin)) ** p, -1)\n",
    "        return C\n",
    "\n",
    "    @staticmethod\n",
    "    def ave(u, u1, tau):\n",
    "        \"Barycenter subroutine, used by kinetic acceleration through extrapolation.\"\n",
    "        return tau * u + (1 - tau) * u1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sinkhorn = SinkhornDistance(eps=0.1, max_iter=100, reduction=None).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data.float()\n",
    "        \n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        \n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "           \n",
    "        return x\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset(set_dist)\n",
    "loader = DataLoader(dataset, batch_size = 12, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepSet(\n",
       "  (feature_extractor): Sequential(\n",
       "    (0): Linear(in_features=2, out_features=50, bias=True)\n",
       "    (1): ELU(alpha=1.0, inplace=True)\n",
       "    (2): Linear(in_features=50, out_features=100, bias=True)\n",
       "    (3): ELU(alpha=1.0, inplace=True)\n",
       "    (4): Linear(in_features=100, out_features=36, bias=True)\n",
       "  )\n",
       "  (regressor): Sequential(\n",
       "    (0): Linear(in_features=36, out_features=30, bias=True)\n",
       "    (1): ELU(alpha=1.0, inplace=True)\n",
       "    (2): Linear(in_features=30, out_features=30, bias=True)\n",
       "    (3): ELU(alpha=1.0, inplace=True)\n",
       "    (4): Linear(in_features=30, out_features=10, bias=True)\n",
       "    (5): ELU(alpha=1.0, inplace=True)\n",
       "    (6): Linear(in_features=10, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DeepSet(2, 36).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "checkpoint = torch.load('normal_2D_flat_newexpt1.pt')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "loss = checkpoint['loss']\n",
    "\n",
    "model.train()\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wasserstein distance has the following properties: \n",
    "1) W(aX,aY) = |a|W(X,Y)\n",
    "2) W(X+x, Y+x) = W(X,Y)\n",
    "\n",
    "Only implement these properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1137, grad_fn=<DivBackward0>)\n",
      "tensor(0.1380, grad_fn=<DivBackward0>)\n",
      "tensor(0.0920, grad_fn=<DivBackward0>)\n",
      "tensor(0.1266, grad_fn=<DivBackward0>)\n",
      "tensor(0.0854, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 500\n",
    "running_loss = []\n",
    "\n",
    "for t in range(num_epochs):\n",
    "    for n_batch, batch in enumerate(loader):\n",
    "        n_data = Variable(batch.to(device), requires_grad=True)\n",
    "        a = torch.rand(1).to(device)\n",
    "        b = torch.rand(2).to(device)\n",
    "       \n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        y = model(n_data)\n",
    "        y_a = model(a*n_data)\n",
    "        y_translate = model(n_data + b)\n",
    "        \n",
    "        loss = 0\n",
    "       \n",
    "        for i in range(len(batch)):\n",
    "            for j in range(i+1,len(batch)):\n",
    "                \n",
    "                y_ij = torch.norm(y[i]-y[j], p=2)\n",
    "                w_ij = sinkhorn(n_data[i],n_data[j]) \n",
    "                \n",
    "                ya_ij = torch.norm(y_a[i]-y_a[j], p=2)\n",
    "                y_translate_ij = torch.norm(y_translate[i]-y_translate[j], p=2)\n",
    "                \n",
    "                diff_translate_ij = torch.norm(y_translate[i]-y[j], p=2)**2\n",
    "                \n",
    "    \n",
    "                loss += torch.norm(y_ij-w_ij, p=2) \n",
    "        \n",
    "                del w_ij\n",
    "        #TODO FIX THE LAST TERMS WITH PAIRWISE DISTANCES (SEE PYTORCH CODE)\n",
    "        \n",
    "        \n",
    "        loss = loss/(len(batch)*(len(batch)-1)/2)\n",
    "        \n",
    "       \n",
    "        loss.backward()\n",
    "    \n",
    "        optimizer.step()\n",
    "    \n",
    "        \n",
    "    running_loss.append(loss)\n",
    "    print(loss)\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "           \n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss\n",
    "            \n",
    "            }, 'normal_2D_flat_newexpt1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(running_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0.1009], grad_fn=<DivBackward0>),\n",
       " tensor([0.1558], grad_fn=<DivBackward0>),\n",
       " tensor([0.1191], grad_fn=<DivBackward0>),\n",
       " tensor([0.0917], grad_fn=<DivBackward0>),\n",
       " tensor([0.1576], grad_fn=<DivBackward0>),\n",
       " tensor([0.1055], grad_fn=<DivBackward0>),\n",
       " tensor([0.0932], grad_fn=<DivBackward0>),\n",
       " tensor([0.1156], grad_fn=<DivBackward0>),\n",
       " tensor([0.1123], grad_fn=<DivBackward0>),\n",
       " tensor([0.1160], grad_fn=<DivBackward0>),\n",
       " tensor([0.1275], grad_fn=<DivBackward0>),\n",
       " tensor([0.1274], grad_fn=<DivBackward0>),\n",
       " tensor([0.1007], grad_fn=<DivBackward0>),\n",
       " tensor([0.1086], grad_fn=<DivBackward0>),\n",
       " tensor([0.1110], grad_fn=<DivBackward0>),\n",
       " tensor([0.0891], grad_fn=<DivBackward0>),\n",
       " tensor([0.1486], grad_fn=<DivBackward0>),\n",
       " tensor([0.1146], grad_fn=<DivBackward0>),\n",
       " tensor([0.1175], grad_fn=<DivBackward0>),\n",
       " tensor([0.1047], grad_fn=<DivBackward0>),\n",
       " tensor([0.1285], grad_fn=<DivBackward0>),\n",
       " tensor([0.1110], grad_fn=<DivBackward0>),\n",
       " tensor([0.1140], grad_fn=<DivBackward0>),\n",
       " tensor([0.0984], grad_fn=<DivBackward0>),\n",
       " tensor([0.1228], grad_fn=<DivBackward0>),\n",
       " tensor([0.1329], grad_fn=<DivBackward0>),\n",
       " tensor([0.0829], grad_fn=<DivBackward0>),\n",
       " tensor([0.1173], grad_fn=<DivBackward0>),\n",
       " tensor([0.1189], grad_fn=<DivBackward0>),\n",
       " tensor([0.1167], grad_fn=<DivBackward0>),\n",
       " tensor([0.1177], grad_fn=<DivBackward0>),\n",
       " tensor([0.1585], grad_fn=<DivBackward0>),\n",
       " tensor([0.1182], grad_fn=<DivBackward0>),\n",
       " tensor([0.1017], grad_fn=<DivBackward0>),\n",
       " tensor([0.1318], grad_fn=<DivBackward0>),\n",
       " tensor([0.1273], grad_fn=<DivBackward0>),\n",
       " tensor([0.1406], grad_fn=<DivBackward0>),\n",
       " tensor([0.0979], grad_fn=<DivBackward0>),\n",
       " tensor([0.1310], grad_fn=<DivBackward0>),\n",
       " tensor([0.0875], grad_fn=<DivBackward0>),\n",
       " tensor([0.0965], grad_fn=<DivBackward0>),\n",
       " tensor([0.1057], grad_fn=<DivBackward0>),\n",
       " tensor([0.1307], grad_fn=<DivBackward0>),\n",
       " tensor([0.0954], grad_fn=<DivBackward0>),\n",
       " tensor([0.1274], grad_fn=<DivBackward0>),\n",
       " tensor([0.1056], grad_fn=<DivBackward0>),\n",
       " tensor([0.1249], grad_fn=<DivBackward0>),\n",
       " tensor([0.0896], grad_fn=<DivBackward0>),\n",
       " tensor([0.1124], grad_fn=<DivBackward0>),\n",
       " tensor([0.1141], grad_fn=<DivBackward0>),\n",
       " tensor([0.1254], grad_fn=<DivBackward0>),\n",
       " tensor([0.1102], grad_fn=<DivBackward0>),\n",
       " tensor([0.0884], grad_fn=<DivBackward0>),\n",
       " tensor([0.1024], grad_fn=<DivBackward0>),\n",
       " tensor([0.1366], grad_fn=<DivBackward0>),\n",
       " tensor([0.1121], grad_fn=<DivBackward0>),\n",
       " tensor([0.1510], grad_fn=<DivBackward0>),\n",
       " tensor([0.1467], grad_fn=<DivBackward0>),\n",
       " tensor([0.1036], grad_fn=<DivBackward0>),\n",
       " tensor([0.0844], grad_fn=<DivBackward0>),\n",
       " tensor([0.1155], grad_fn=<DivBackward0>),\n",
       " tensor([0.1042], grad_fn=<DivBackward0>),\n",
       " tensor([0.1629], grad_fn=<DivBackward0>),\n",
       " tensor([0.1271], grad_fn=<DivBackward0>),\n",
       " tensor([0.1456], grad_fn=<DivBackward0>),\n",
       " tensor([0.1245], grad_fn=<DivBackward0>),\n",
       " tensor([0.1054], grad_fn=<DivBackward0>),\n",
       " tensor([0.1239], grad_fn=<DivBackward0>),\n",
       " tensor([0.0799], grad_fn=<DivBackward0>),\n",
       " tensor([0.1333], grad_fn=<DivBackward0>),\n",
       " tensor([0.0772], grad_fn=<DivBackward0>),\n",
       " tensor([0.1207], grad_fn=<DivBackward0>),\n",
       " tensor([0.1025], grad_fn=<DivBackward0>),\n",
       " tensor([0.1326], grad_fn=<DivBackward0>),\n",
       " tensor([0.1241], grad_fn=<DivBackward0>),\n",
       " tensor([0.1052], grad_fn=<DivBackward0>),\n",
       " tensor([0.1037], grad_fn=<DivBackward0>),\n",
       " tensor([0.0895], grad_fn=<DivBackward0>),\n",
       " tensor([0.1118], grad_fn=<DivBackward0>),\n",
       " tensor([0.1236], grad_fn=<DivBackward0>),\n",
       " tensor([0.1081], grad_fn=<DivBackward0>),\n",
       " tensor([0.0867], grad_fn=<DivBackward0>),\n",
       " tensor([0.1215], grad_fn=<DivBackward0>),\n",
       " tensor([0.1406], grad_fn=<DivBackward0>),\n",
       " tensor([0.1057], grad_fn=<DivBackward0>),\n",
       " tensor([0.1066], grad_fn=<DivBackward0>),\n",
       " tensor([0.0916], grad_fn=<DivBackward0>),\n",
       " tensor([0.1010], grad_fn=<DivBackward0>),\n",
       " tensor([0.1406], grad_fn=<DivBackward0>),\n",
       " tensor([0.0874], grad_fn=<DivBackward0>),\n",
       " tensor([0.1336], grad_fn=<DivBackward0>),\n",
       " tensor([0.1084], grad_fn=<DivBackward0>),\n",
       " tensor([0.1223], grad_fn=<DivBackward0>),\n",
       " tensor([0.1080], grad_fn=<DivBackward0>),\n",
       " tensor([0.0992], grad_fn=<DivBackward0>),\n",
       " tensor([0.1206], grad_fn=<DivBackward0>),\n",
       " tensor([0.1314], grad_fn=<DivBackward0>),\n",
       " tensor([0.1137], grad_fn=<DivBackward0>),\n",
       " tensor([0.1185], grad_fn=<DivBackward0>),\n",
       " tensor([0.1257], grad_fn=<DivBackward0>),\n",
       " tensor([0.1080], grad_fn=<DivBackward0>),\n",
       " tensor([0.0964], grad_fn=<DivBackward0>),\n",
       " tensor([0.1094], grad_fn=<DivBackward0>),\n",
       " tensor([0.1105], grad_fn=<DivBackward0>),\n",
       " tensor([0.1272], grad_fn=<DivBackward0>),\n",
       " tensor([0.1437], grad_fn=<DivBackward0>),\n",
       " tensor([0.1523], grad_fn=<DivBackward0>),\n",
       " tensor([0.1159], grad_fn=<DivBackward0>),\n",
       " tensor([0.1253], grad_fn=<DivBackward0>),\n",
       " tensor([0.0943], grad_fn=<DivBackward0>),\n",
       " tensor([0.1005], grad_fn=<DivBackward0>),\n",
       " tensor([0.1064], grad_fn=<DivBackward0>),\n",
       " tensor([0.1212], grad_fn=<DivBackward0>),\n",
       " tensor([0.1231], grad_fn=<DivBackward0>),\n",
       " tensor([0.1157], grad_fn=<DivBackward0>),\n",
       " tensor([0.1110], grad_fn=<DivBackward0>),\n",
       " tensor([0.0895], grad_fn=<DivBackward0>),\n",
       " tensor([0.1057], grad_fn=<DivBackward0>),\n",
       " tensor([0.1018], grad_fn=<DivBackward0>),\n",
       " tensor([0.1432], grad_fn=<DivBackward0>),\n",
       " tensor([0.1295], grad_fn=<DivBackward0>),\n",
       " tensor([0.1127], grad_fn=<DivBackward0>),\n",
       " tensor([0.1146], grad_fn=<DivBackward0>),\n",
       " tensor([0.1286], grad_fn=<DivBackward0>),\n",
       " tensor([0.1129], grad_fn=<DivBackward0>),\n",
       " tensor([0.1200], grad_fn=<DivBackward0>),\n",
       " tensor([0.1140], grad_fn=<DivBackward0>),\n",
       " tensor([0.1042], grad_fn=<DivBackward0>),\n",
       " tensor([0.1149], grad_fn=<DivBackward0>),\n",
       " tensor([0.1139], grad_fn=<DivBackward0>),\n",
       " tensor([0.1290], grad_fn=<DivBackward0>),\n",
       " tensor([0.1581], grad_fn=<DivBackward0>),\n",
       " tensor([0.0753], grad_fn=<DivBackward0>),\n",
       " tensor([0.0952], grad_fn=<DivBackward0>),\n",
       " tensor([0.0805], grad_fn=<DivBackward0>),\n",
       " tensor([0.0929], grad_fn=<DivBackward0>),\n",
       " tensor([0.0960], grad_fn=<DivBackward0>),\n",
       " tensor([0.1070], grad_fn=<DivBackward0>),\n",
       " tensor([0.1292], grad_fn=<DivBackward0>),\n",
       " tensor([0.1075], grad_fn=<DivBackward0>),\n",
       " tensor([0.1151], grad_fn=<DivBackward0>),\n",
       " tensor([0.0870], grad_fn=<DivBackward0>),\n",
       " tensor([0.0931], grad_fn=<DivBackward0>),\n",
       " tensor([0.1183], grad_fn=<DivBackward0>),\n",
       " tensor([0.1614], grad_fn=<DivBackward0>),\n",
       " tensor([0.1293], grad_fn=<DivBackward0>),\n",
       " tensor([0.1178], grad_fn=<DivBackward0>),\n",
       " tensor([0.0890], grad_fn=<DivBackward0>),\n",
       " tensor([0.1362], grad_fn=<DivBackward0>),\n",
       " tensor([0.0907], grad_fn=<DivBackward0>)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test ground truth\n",
    "#Cov mat_1 = ID, Cov mat_2 = [[1,.5], [.5,1]], m_1 = (0,0) , m_2 = (0,1)\n",
    "#Real Wass dist^2 = ||m_1 - m_2||^2 + (4-\\sqrt(2)-\\sqrt(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.distributions.multivariate_normal.MultivariateNormal(torch.zeros(2), torch.eye(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = m.sample([250]).view(1,-1,2)\n",
    "m2 = m.sample([250]).view(1,-1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    " n = torch.distributions.multivariate_normal.MultivariateNormal(torch.tensor([0.0, 1.0]), torch.tensor([[1,.5],[.5,1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = n.sample([250]).view(1,-1,2)\n",
    "n2 = n.sample([250]).view(1,-1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4294, 2.4464]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3029, 2.4141]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3682, 3.2126]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(n1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4177, 3.2026]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(n2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1380])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sinkhorn(m1,n2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.ones(250,2).view(1,-1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = torch.zeros(250,2).view(1,-1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5725, 4.3866]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4531, 2.3515]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.0000])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculated distance is 1.997\n",
    "sinkhorn(A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = torch.distributions.bernoulli.Bernoulli(torch.tensor([.3, .3]))\n",
    "D = torch.distributions.bernoulli.Bernoulli(torch.tensor([.5, .5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "C1 = C.sample([250]).view(1,-1,2)\n",
    "D1 = D.sample([250]).view(1,-1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4259, 2.9401]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(C1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5356, 3.2694]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(D1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3313])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we get .3289\n",
    "sinkhorn(C1,D1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.5402])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sinkhorn(m1,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
