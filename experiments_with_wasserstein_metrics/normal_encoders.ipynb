{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.spatial import KDTree\n",
    "from scipy.stats import wasserstein_distance\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd.variable import Variable\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(5,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.rand(5,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = nn.PairwiseDistance(p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2827)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(x[0]-y[0],p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2827, 0.4016, 0.9251, 0.3960, 0.7157])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device('cuda') if torch.cuda.is_available else torch.device('cpu')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_dist = []\n",
    "\n",
    "\n",
    "for i in range(50): \n",
    "    m = torch.distributions.normal.Normal(torch.tensor([0.3]), torch.tensor([0.5]))\n",
    "    x = m.sample([100])\n",
    "    set_dist.append(x) \n",
    "    \n",
    "for i in range(50): \n",
    "    m = torch.distributions.normal.Normal(torch.tensor([0.0]), torch.tensor([1.0]))\n",
    "    x = m.sample([100])\n",
    "    set_dist.append(x) \n",
    "    \n",
    "for i in range(50): \n",
    "    m = torch.distributions.normal.Normal(torch.tensor([-.5]), torch.tensor([0.75]))\n",
    "    x = m.sample([100])\n",
    "    set_dist.append(x) \n",
    "    \n",
    "for i in range(50): \n",
    "    m = torch.distributions.normal.Normal(torch.tensor([1.0]), torch.tensor([1.0]))\n",
    "    x = m.sample([100])\n",
    "    set_dist.append(x) \n",
    "    \n",
    "for i in range(50): \n",
    "    m = torch.distributions.normal.Normal(torch.tensor([-.3]), torch.tensor([0.1]))\n",
    "    x = m.sample([100])\n",
    "    set_dist.append(x) \n",
    "    \n",
    "for i in range(50): \n",
    "    m = torch.distributions.normal.Normal(torch.tensor([0.7]), torch.tensor([0.2]))\n",
    "    x = m.sample([100])\n",
    "    set_dist.append(x) \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_dist = torch.stack(set_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300, 100, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Set2Set(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, act_fn=nn.Tanh, num_layers=1):\n",
    "        '''\n",
    "        Args:\n",
    "            input_dim: input dim of Set2Set. \n",
    "            hidden_dim: the dim of set representation, which is also the INPUT dimension of \n",
    "                the LSTM in Set2Set. \n",
    "                This is a concatenation of weighted sum of embedding (dim input_dim), and the LSTM\n",
    "                hidden/output (dim: self.lstm_output_dim).\n",
    "        '''\n",
    "        super(Set2Set, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        if hidden_dim <= input_dim:\n",
    "            print('ERROR: Set2Set output_dim should be larger than input_dim')\n",
    "        # the hidden is a concatenation of weighted sum of embedding and LSTM output\n",
    "        self.lstm_output_dim = hidden_dim - input_dim\n",
    "        self.lstm = nn.LSTM(hidden_dim, input_dim, num_layers=num_layers, batch_first=True)\n",
    "\n",
    "        # convert back to dim of input_dim\n",
    "       # self.pred = nn.Linear(hidden_dim, input_dim)\n",
    "        self.pred = nn.Linear(hidden_dim,4)\n",
    "        self.act = act_fn()\n",
    "\n",
    "    def forward(self, embedding):\n",
    "        '''\n",
    "        Args:\n",
    "            embedding: [batch_size x n x d] embedding matrix\n",
    "        Returns:\n",
    "            aggregated: [batch_size x d] vector representation of all embeddings\n",
    "        '''\n",
    "        batch_size = embedding.size()[0]\n",
    "        n = embedding.size()[1]\n",
    "\n",
    "        hidden = (torch.zeros(self.num_layers, batch_size, self.lstm_output_dim).cuda(),\n",
    "                  torch.zeros(self.num_layers, batch_size, self.lstm_output_dim).cuda())\n",
    "\n",
    "        q_star = torch.zeros(batch_size, 1, self.hidden_dim).cuda()\n",
    "        for i in range(n):\n",
    "            # q: batch_size x 1 x input_dim\n",
    "            q, hidden = self.lstm(q_star, hidden)\n",
    "            # e: batch_size x n x 1\n",
    "            e = embedding @ torch.transpose(q, 1, 2)\n",
    "            a = nn.Softmax(dim=1)(e)\n",
    "            r = torch.sum(a * embedding, dim=1, keepdim=True)\n",
    "            q_star = torch.cat((q, r), dim=2)\n",
    "        q_star = torch.squeeze(q_star, dim=1)\n",
    "        out = self.act(self.pred(q_star))\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepSet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, set_features):\n",
    "        super(DeepSet, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = set_features\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Linear(in_features, 50),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Linear(50, 100),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Linear(100, set_features)\n",
    "        )\n",
    "\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(set_features, 30),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Linear(30, 30),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Linear(30, 10),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Linear(10, 2),\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, input):\n",
    "        x = input\n",
    "        x = self.feature_extractor(x)\n",
    "        x = x.sum(dim=1)\n",
    "        x = self.regressor(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\" Set Encoder \n",
    "    \"\"\"\n",
    "    def __init__(self, dim_Q, dim_K, dim_V, d_model, num_heads, ln=False, skip=True):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.dim_V = dim_V\n",
    "        self.num_heads = num_heads\n",
    "        self.skip = skip\n",
    "       # self.s_max = s_max\n",
    "        #Maximum set size\n",
    "        self.d_model = d_model\n",
    "        self.fc_q = nn.Linear(dim_Q, d_model)\n",
    "        self.fc_k = nn.Linear(dim_K, d_model)\n",
    "        self.fc_v = nn.Linear(dim_K, d_model)\n",
    "        if ln:\n",
    "            self.ln0 = nn.LayerNorm(d_model)\n",
    "            self.ln1 = nn.LayerNorm(d_model)\n",
    "        #This is the classic pointwise feedforward in \"Attention is All you need\"\n",
    "        self.ff = nn.Sequential(\n",
    "        nn.Linear(d_model, 4 * d_model),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(4 * d_model, d_model))\n",
    "        # I have experimented with just a smaller version of this \n",
    "       # self.fc_o = nn.Linear(d_model,d_model)\n",
    "        \n",
    "     #   self.fc_rep = nn.Linear(s_max, 1)\n",
    "#number of heads must divide output size = d_model\n",
    "        \n",
    "\n",
    "    def forward(self, Q, K):\n",
    "        Q = self.fc_q(Q)\n",
    "      \n",
    "        K, V = self.fc_k(K), self.fc_v(K)\n",
    "\n",
    "        dim_split = self.d_model // self.num_heads\n",
    "        Q_ = torch.cat(Q.split(dim_split, 2), 0)\n",
    "        K_ = torch.cat(K.split(dim_split, 2), 0)\n",
    "        V_ = torch.cat(V.split(dim_split, 2), 0)\n",
    "  \n",
    "\n",
    "        A = torch.softmax(Q_.bmm(K_.transpose(-2,-1))/math.sqrt(self.d_model), dim=-1)\n",
    "        A_1 = A.bmm(V_)\n",
    "        \n",
    " \n",
    "        O = torch.cat((A_1).split(Q.size(0), 0), 2)\n",
    "       \n",
    "        O = torch.cat((Q_ + A_1).split(Q.size(0), 0), 2) if getattr(self, 'skip', True) else \\\n",
    "             torch.cat((A_1).split(Q.size(0), 0), 2)\n",
    "        O = O if getattr(self, 'ln0', None) is None else self.ln0(O)\n",
    "       # O = O + F.relu(self.fc_o(O)) if getattr(self, 'skip', None) is None else F.relu(self.fc_o(O))\n",
    "        # For the classic transformers paper it is \n",
    "        O = O + self.ff(O)\n",
    "        O = O if getattr(self, 'ln1', None) is None else self.ln1(O)\n",
    "        O = torch.mean(O,dim=1)\n",
    "#         O = pad_sequence(O, batch_first=True, padding_value=0)\n",
    "#         O = O.transpose(-2,-1)\n",
    "#         O = F.pad(O, (0, self.s_max- O.shape[-1]), 'constant', 0)\n",
    "      #  O = self.fc_rep(O)\n",
    "       # O = self.fc_rep(O.transpose(-2,-1))\n",
    "      #  O = O.squeeze()\n",
    "\n",
    "        return O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, dim_in=18, dim_out=8, num_heads=2, ln=True, skip=True):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.Encoder = Encoder(dim_in, dim_in, dim_in, dim_out, num_heads, ln=ln, skip=skip)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.Encoder(X, X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-15\n",
    "\"\"\"Approximating KL divergences between two probability densities using samples. \n",
    "    It is buggy. Use at your own peril\n",
    "\"\"\"\n",
    "\n",
    "def knn_distance(point, sample, k):\n",
    "    \"\"\" Euclidean distance from `point` to it's `k`-Nearest\n",
    "    Neighbour in `sample` \"\"\"\n",
    "    norms = np.linalg.norm(sample-point, axis=1)\n",
    "    return np.sort(norms)[k]\n",
    "\n",
    "\n",
    "def verify_sample_shapes(s1, s2, k):\n",
    "    # Expects [N, D]\n",
    "    assert(len(s1.shape) == len(s2.shape) == 2)\n",
    "    # Check dimensionality of sample is identical\n",
    "    assert(s1.shape[1] == s2.shape[1])\n",
    "\n",
    "\n",
    "def naive_estimator(s1, s2, k=1):\n",
    "    \"\"\" KL-Divergence estimator using brute-force (numpy) k-NN\n",
    "        s1: (N_1,D) Sample drawn from distribution P\n",
    "        s2: (N_2,D) Sample drawn from distribution Q\n",
    "        k: Number of neighbours considered (default 1)\n",
    "        return: estimated D(P|Q)\n",
    "    \"\"\"\n",
    "    verify_sample_shapes(s1, s2, k)\n",
    "\n",
    "    n, m = len(s1), len(s2)\n",
    "    D = np.log(m / (n - 1))\n",
    "    d = float(s1.shape[1])\n",
    "\n",
    "    for p1 in s1:\n",
    "        nu = knn_distance(p1, s2, k-1)  # -1 because 'p1' is not in 's2'\n",
    "        rho = knn_distance(p1, s1, k)\n",
    "        D += (d/n)*np.log((nu/rho)+eps)\n",
    "    return D\n",
    "\n",
    "\n",
    "def scipy_estimator(s1, s2, k=1):\n",
    "    \"\"\" KL-Divergence estimator using scipy's KDTree\n",
    "        s1: (N_1,D) Sample drawn from distribution P\n",
    "        s2: (N_2,D) Sample drawn from distribution Q\n",
    "        k: Number of neighbours considered (default 1)\n",
    "        return: estimated D(P|Q)\n",
    "    \"\"\"\n",
    "    verify_sample_shapes(s1, s2, k)\n",
    "\n",
    "    n, m = len(s1), len(s2)\n",
    "    d = float(s1.shape[1])\n",
    "    D = np.log(m / (n - 1))\n",
    "\n",
    "    nu_d,  nu_i   = KDTree(s2).query(s1, k)\n",
    "    rho_d, rhio_i = KDTree(s1).query(s1, k+1)\n",
    "\n",
    "    # KTree.query returns different shape in k==1 vs k > 1\n",
    "    if k > 1:\n",
    "        D += (d/n)*np.sum(np.log(nu_d[::, -1]/rho_d[::, -1]))\n",
    "    else:\n",
    "        D += (d/n)*np.sum(np.log(nu_d/rho_d[::, -1]))\n",
    "\n",
    "    return D\n",
    "\n",
    "\n",
    "def skl_estimator(s1, s2, k=1):\n",
    "    \"\"\" KL-Divergence estimator using scikit-learn's NearestNeighbours\n",
    "        s1: (N_1,D) Sample drawn from distribution P\n",
    "        s2: (N_2,D) Sample drawn from distribution Q\n",
    "        k: Number of neighbours considered (default 1)\n",
    "        return: estimated D(P|Q)\n",
    "    \"\"\"\n",
    "    verify_sample_shapes(s1, s2, k)\n",
    "\n",
    "    n, m = len(s1), len(s2)\n",
    "    d = float(s1.shape[1])\n",
    "    D = np.log(m / (n - 1))\n",
    "\n",
    "    s1_neighbourhood = NearestNeighbors(k+1, 10).fit(s1)\n",
    "    s2_neighbourhood = NearestNeighbors(k, 10).fit(s2)\n",
    "\n",
    "    for p1 in s1:\n",
    "        s1_distances, indices = s1_neighbourhood.kneighbors([p1], k+1)\n",
    "        s2_distances, indices = s2_neighbourhood.kneighbors([p1], k)\n",
    "        rho = s1_distances[0][-1]\n",
    "        nu = s2_distances[0][-1]\n",
    "        D += (d/n)*np.log(nu/rho)\n",
    "    return D\n",
    "\n",
    "\n",
    "# List of all estimators\n",
    "Estimators = [naive_estimator, scipy_estimator, skl_estimator]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinkhornDistance(nn.Module):\n",
    "    r\"\"\"\n",
    "    Given two empirical measures each with :math:`P_1` locations\n",
    "    :math:`x\\in\\mathbb{R}^{D_1}` and :math:`P_2` locations :math:`y\\in\\mathbb{R}^{D_2}`,\n",
    "    outputs an approximation of the regularized OT cost for point clouds.\n",
    "    Args:\n",
    "        eps (float): regularization coefficient\n",
    "        max_iter (int): maximum number of Sinkhorn iterations\n",
    "        reduction (string, optional): Specifies the reduction to apply to the output:\n",
    "            'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n",
    "            'mean': the sum of the output will be divided by the number of\n",
    "            elements in the output, 'sum': the output will be summed. Default: 'none'\n",
    "    Shape:\n",
    "        - Input: :math:`(N, P_1, D_1)`, :math:`(N, P_2, D_2)`\n",
    "        - Output: :math:`(N)` or :math:`()`, depending on `reduction`\n",
    "    \"\"\"\n",
    "    def __init__(self, eps, max_iter, reduction='none'):\n",
    "        super(SinkhornDistance, self).__init__()\n",
    "        self.eps = eps\n",
    "        self.max_iter = max_iter\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        # The Sinkhorn algorithm takes as input three variables :\n",
    "        C = self._cost_matrix(x, y)  # Wasserstein cost function\n",
    "        x_points = x.shape[-2]\n",
    "        y_points = y.shape[-2]\n",
    "        if x.dim() == 2:\n",
    "            batch_size = 1\n",
    "        else:\n",
    "            batch_size = x.shape[0]\n",
    "\n",
    "        # both marginals are fixed with equal weights\n",
    "        mu = torch.empty(batch_size, x_points, dtype=torch.float,\n",
    "                         requires_grad=False).fill_(1.0 / x_points).to(device).squeeze()\n",
    "        nu = torch.empty(batch_size, y_points, dtype=torch.float,\n",
    "                         requires_grad=False).fill_(1.0 / y_points).to(device).squeeze()\n",
    "\n",
    "        u = torch.zeros_like(mu).to(device)\n",
    "        v = torch.zeros_like(nu).to(device)\n",
    "        # To check if algorithm terminates because of threshold\n",
    "        # or max iterations reached\n",
    "        actual_nits = 0\n",
    "        # Stopping criterion\n",
    "        thresh = 1e-1\n",
    "\n",
    "        # Sinkhorn iterations\n",
    "        for i in range(self.max_iter):\n",
    "            u1 = u  # useful to check the update\n",
    "            u = self.eps * (torch.log(mu+1e-8) - torch.logsumexp(self.M(C, u, v), dim=-1)) + u\n",
    "            v = self.eps * (torch.log(nu+1e-8) - torch.logsumexp(self.M(C, u, v).transpose(-2, -1), dim=-1)) + v\n",
    "            err = (u - u1).abs().sum(-1).mean()\n",
    "\n",
    "            actual_nits += 1\n",
    "            if err.item() < thresh:\n",
    "                break\n",
    "\n",
    "        U, V = u, v\n",
    "        # Transport plan pi = diag(a)*K*diag(b)\n",
    "        pi = torch.exp(self.M(C, U, V))\n",
    "        # Sinkhorn distance\n",
    "        cost = torch.sum(pi * C, dim=(-2, -1))\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            cost = cost.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            cost = cost.sum()\n",
    "\n",
    "      #  return cost, pi, C\n",
    "        return cost\n",
    "\n",
    "    def M(self, C, u, v):\n",
    "        \"Modified cost for logarithmic updates\"\n",
    "        \"$M_{ij} = (-c_{ij} + u_i + v_j) / \\epsilon$\"\n",
    "        return (-C + u.unsqueeze(-1) + v.unsqueeze(-2)) / self.eps\n",
    "\n",
    "    @staticmethod\n",
    "    def _cost_matrix(x, y, p=2):\n",
    "        \"Returns the matrix of $|x_i-y_j|^p$.\"\n",
    "        x_col = x.unsqueeze(-2)\n",
    "        y_lin = y.unsqueeze(-3)\n",
    "        C = torch.sum((torch.abs(x_col - y_lin)) ** p, -1)\n",
    "        return C\n",
    "\n",
    "    @staticmethod\n",
    "    def ave(u, u1, tau):\n",
    "        \"Barycenter subroutine, used by kinetic acceleration through extrapolation.\"\n",
    "        return tau * u + (1 - tau) * u1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sinkhorn = SinkhornDistance(eps=0.1, max_iter=100, reduction=None).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data.float()\n",
    "        \n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        \n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "           \n",
    "        return x\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset(set_dist)\n",
    "loader = DataLoader(dataset, batch_size = 12, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepSet(\n",
       "  (feature_extractor): Sequential(\n",
       "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
       "    (1): ELU(alpha=1.0, inplace=True)\n",
       "    (2): Linear(in_features=50, out_features=100, bias=True)\n",
       "    (3): ELU(alpha=1.0, inplace=True)\n",
       "    (4): Linear(in_features=100, out_features=36, bias=True)\n",
       "  )\n",
       "  (regressor): Sequential(\n",
       "    (0): Linear(in_features=36, out_features=30, bias=True)\n",
       "    (1): ELU(alpha=1.0, inplace=True)\n",
       "    (2): Linear(in_features=30, out_features=30, bias=True)\n",
       "    (3): ELU(alpha=1.0, inplace=True)\n",
       "    (4): Linear(in_features=30, out_features=10, bias=True)\n",
       "    (5): ELU(alpha=1.0, inplace=True)\n",
       "    (6): Linear(in_features=10, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DeepSet(1, 36).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "model.load_state_dict(torch.load('normal_encode_1D_600.pkl'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wasserstein distance has the following properties: \n",
    "1) W(aX,aY) = |a|W(X,Y)\n",
    "2) W(X+x, Y+x) = W(X,Y)\n",
    "3) W^2_2(X+x,Y) = ||x+E(X)-E(Y)|| + W^2_2(X,Y)\n",
    "Next step is to implement these properties "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 500\n",
    "running_loss = []\n",
    "for t in range(num_epochs):\n",
    "    for n_batch, batch in enumerate(loader):\n",
    "        n_data = Variable(batch.to(device), requires_grad=True)\n",
    "        a = torch.rand(1).to(device)\n",
    "        b = torch.rand(1).to(device)\n",
    "       \n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        y = model(n_data)\n",
    "        y_a = model(a*n_data)\n",
    "        y_translate = model(n_data + b)\n",
    "        \n",
    "        loss = 0\n",
    "       \n",
    "        for i in range(len(batch)):\n",
    "            for j in range(i+1,len(batch)):\n",
    "                \n",
    "                y_ij = torch.norm(y[i]-y[j], p=2)\n",
    "                w_ij = sinkhorn(n_data[i],n_data[j]) \n",
    "                \n",
    "                ya_ij = torch.norm(y_a[i]-y_a[j], p=2)\n",
    "                y_translate_ij = torch.norm(y_translate[i]-y_translate[j], p=2)\n",
    "                \n",
    "                diff_translate_ij = torch.norm(y_translate[i]-y[j], p=2)**2\n",
    "                \n",
    "    \n",
    "                loss += torch.norm(y_ij-w_ij, p=2) + (ya_ij-a*y_ij)**2 + (y_translate_ij- y_ij)**2 + (diff_translate_ij - (b + torch.mean(n_data[i]- n_data[j]))**2 - y_ij**2)**2\n",
    "                                              \n",
    "                \n",
    "                del w_ij\n",
    "        #TODO FIX THE LAST TERMS WITH PAIRWISE DISTANCES (SEE PYTORCH CODE)\n",
    "        \n",
    "        \n",
    "        loss = loss/(len(batch)*(len(batch)-1)/2)\n",
    "       \n",
    "        loss.backward()\n",
    "       \n",
    "        optimizer.step()\n",
    "    \n",
    "        \n",
    "    running_loss.append(loss)\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normal_encode_1D pkl is after 100 epochs. Do not do this again\n",
    "torch.save(model.state_dict(),'normal_encode_1D_600.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            \n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss\n",
    "            \n",
    "            }, 'normal_encode_1D_600epoch.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions import normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "N1 = normal.Normal(torch.tensor([0.0]), torch.tensor([0.01]))\n",
    "N2 = normal.Normal(torch.tensor([0.0]), torch.tensor([0.001]))\n",
    "N3 = normal.Normal(torch.tensor([0.0]), torch.tensor([0.002]))\n",
    "N4 = normal.Normal(torch.tensor([0.0]), torch.tensor([0.003]))\n",
    "N5 = normal.Normal(torch.tensor([0.0]), torch.tensor([0.004]))\n",
    "N6 = normal.Normal(torch.tensor([0.0]), torch.tensor([0.005]))\n",
    "N7 = normal.Normal(torch.tensor([0.0]), torch.tensor([0.006]))\n",
    "N8 = normal.Normal(torch.tensor([0.0]), torch.tensor([0.007]))\n",
    "N9 = normal.Normal(torch.tensor([0.0]), torch.tensor([0.008]))\n",
    "N0 = normal.Normal(torch.tensor([0.0]), torch.tensor([0.009]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n1 = N1.sample([500]).view(1,-1,1)\n",
    "n2 = N2.sample([500]).view(1,-1,1)\n",
    "n3 = N3.sample([500]).view(1,-1,1)\n",
    "n4 = N4.sample([500]).view(1,-1,1)\n",
    "n5 = N5.sample([500]).view(1,-1,1)\n",
    "n6 = N6.sample([500]).view(1,-1,1)\n",
    "n7 = N7.sample([500]).view(1,-1,1)\n",
    "n8 = N8.sample([500]).view(1,-1,1)\n",
    "n9 = N9.sample([500]).view(1,-1,1)\n",
    "n0 = N0.sample([500]).view(1,-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-16.7333,   2.0709]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(n1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-16.7347,   2.0731]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(n2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-16.7349,   2.0725]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(n3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-16.7346,   2.0730]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(n4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-16.7348,   2.0720]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(n5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-16.7337,   2.0743]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(n6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-16.7346,   2.0716]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(n7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-16.7338,   2.0729]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(n8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-16.7335,   2.0732]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(n9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-16.7328,   2.0738]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(n0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-16.7348,   2.0729]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.zeros(1,500,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
