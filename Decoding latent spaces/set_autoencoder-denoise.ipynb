{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.spatial import KDTree\n",
    "from scipy.stats import wasserstein_distance\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from math import isnan\n",
    "from scipy.optimize import minimize\n",
    "import warnings\n",
    "from sklearn.neighbors import KernelDensity  # display as density curves\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init, Module, Parameter  # PyTorch syntax for optimization problems\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd.variable import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from geomloss import SamplesLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.distributions.distribution import Distribution\n",
    "from torch.distributions import Categorical\n",
    "from torch.distributions import constraints\n",
    "\n",
    "\n",
    "class MixtureSameFamily(Distribution):\n",
    "    r\"\"\"\n",
    "    The `MixtureSameFamily` distribution implements a (batch of) mixture\n",
    "    distribution where all component are from different parameterizations of\n",
    "    the same distribution type. It is parameterized by a `Categorical`\n",
    "    \"selecting distribution\" (over `k` component) and a component\n",
    "    distribution, i.e., a `Distribution` with a rightmost batch shape\n",
    "    (equal to `[k]`) which indexes each (batch of) component.\n",
    "\n",
    "    Examples::\n",
    "\n",
    "        # Construct Gaussian Mixture Model in 1D consisting of 5 equally\n",
    "        # weighted normal distributions\n",
    "        >>> mix = D.Categorical(torch.ones(5,))\n",
    "        >>> comp = D.Normal(torch.randn(5,), torch.rand(5,))\n",
    "        >>> gmm = MixtureSameFamily(mix, comp)\n",
    "\n",
    "        # Construct Gaussian Mixture Modle in 2D consisting of 5 equally\n",
    "        # weighted bivariate normal distributions\n",
    "        >>> mix = D.Categorical(torch.ones(5,))\n",
    "        >>> comp = D.Independent(D.Normal(\n",
    "                     torch.randn(5,2), torch.rand(5,2)), 1)\n",
    "        >>> gmm = MixtureSameFamily(mix, comp)\n",
    "\n",
    "        # Construct a batch of 3 Gaussian Mixture Models in 2D each\n",
    "        # consisting of 5 random weighted bivariate normal distributions\n",
    "        >>> mix = D.Categorical(torch.rand(3,5))\n",
    "        >>> comp = D.Independent(D.Normal(\n",
    "                    torch.randn(3,5,2), torch.rand(3,5,2)), 1)\n",
    "        >>> gmm = MixtureSameFamily(mix, comp)\n",
    "\n",
    "    Args:\n",
    "        mixture_distribution: `torch.distributions.Categorical`-like\n",
    "            instance. Manages the probability of selecting component.\n",
    "            The number of categories must match the rightmost batch\n",
    "            dimension of the `component_distribution`. Must have either\n",
    "            scalar `batch_shape` or `batch_shape` matching\n",
    "            `component_distribution.batch_shape[:-1]`\n",
    "        component_distribution: `torch.distributions.Distribution`-like\n",
    "            instance. Right-most batch dimension indexes component.\n",
    "    \"\"\"\n",
    "    arg_constraints = {}\n",
    "    has_rsample = False\n",
    "\n",
    "    def __init__(self,\n",
    "                 mixture_distribution,\n",
    "                 component_distribution,\n",
    "                 validate_args=None):\n",
    "        self._mixture_distribution = mixture_distribution\n",
    "        self._component_distribution = component_distribution\n",
    "\n",
    "        if not isinstance(self._mixture_distribution, Categorical):\n",
    "            raise ValueError(\" The Mixture distribution needs to be an \"\n",
    "                             \" instance of torch.distribtutions.Categorical\")\n",
    "\n",
    "        if not isinstance(self._component_distribution, Distribution):\n",
    "            raise ValueError(\"The Component distribution need to be an \"\n",
    "                             \"instance of torch.distributions.Distribution\")\n",
    "\n",
    "        # Check that batch size matches\n",
    "        mdbs = self._mixture_distribution.batch_shape\n",
    "        cdbs = self._component_distribution.batch_shape[:-1]\n",
    "        for size1, size2 in zip(reversed(mdbs), reversed(cdbs)):\n",
    "            if size1 != 1 and size2 != 1 and size1 != size2:\n",
    "                raise ValueError(\"`mixture_distribution.batch_shape` ({0}) is not \"\n",
    "                                 \"compatible with `component_distribution.\"\n",
    "                                 \"batch_shape`({1})\".format(mdbs, cdbs))\n",
    "\n",
    "        # Check that the number of mixture component matches\n",
    "        km = self._mixture_distribution.logits.shape[-1]\n",
    "        kc = self._component_distribution.batch_shape[-1]\n",
    "        if km is not None and kc is not None and km != kc:\n",
    "            raise ValueError(\"`mixture_distribution component` ({0}) does not\"\n",
    "                             \" equal `component_distribution.batch_shape[-1]`\"\n",
    "                             \" ({1})\".format(km, kc))\n",
    "        self._num_component = km\n",
    "\n",
    "        event_shape = self._component_distribution.event_shape\n",
    "        self._event_ndims = len(event_shape)\n",
    "        super(MixtureSameFamily, self).__init__(batch_shape=cdbs,\n",
    "                                                event_shape=event_shape,\n",
    "                                                validate_args=validate_args)\n",
    "\n",
    "    def expand(self, batch_shape, _instance=None):\n",
    "        batch_shape = torch.Size(batch_shape)\n",
    "        batch_shape_comp = batch_shape + (self._num_component,)\n",
    "        new = self._get_checked_instance(MixtureSameFamily, _instance)\n",
    "        new._component_distribution = \\\n",
    "            self._component_distribution.expand(batch_shape_comp)\n",
    "        new._mixture_distribution = \\\n",
    "            self._mixture_distribution.expand(batch_shape)\n",
    "        new._num_component = self._num_component\n",
    "        new._event_ndims = self._event_ndims\n",
    "        event_shape = new._component_distribution.event_shape\n",
    "        super(MixtureSameFamily, new).__init__(batch_shape=batch_shape,\n",
    "                                               event_shape=event_shape,\n",
    "                                               validate_args=False)\n",
    "        new._validate_args = self._validate_args\n",
    "        return new\n",
    "\n",
    "\n",
    "    @constraints.dependent_property\n",
    "    def support(self):\n",
    "        # FIXME this may have the wrong shape when support contains batched \n",
    "        # parameters\n",
    "        return self._component_distribution.support\n",
    "\n",
    "    @property\n",
    "    def mixture_distribution(self):\n",
    "        return self._mixture_distribution\n",
    "\n",
    "    @property\n",
    "    def component_distribution(self):\n",
    "        return self._component_distribution\n",
    "\n",
    "    @property\n",
    "    def mean(self):\n",
    "        probs = self._pad_mixture_dimensions(self.mixture_distribution.probs)\n",
    "        return torch.sum(probs * self.component_distribution.mean,\n",
    "                         dim=-1 - self._event_ndims)  # [B, E]\n",
    "\n",
    "    @property\n",
    "    def variance(self):\n",
    "        # Law of total variance: Var(Y) = E[Var(Y|X)] + Var(E[Y|X])\n",
    "        probs = self._pad_mixture_dimensions(self.mixture_distribution.probs)\n",
    "        mean_cond_var = torch.sum(probs * self.component_distribution.variance,\n",
    "                                  dim=-1 - self._event_ndims)\n",
    "        var_cond_mean = torch.sum(probs * (self.component_distribution.mean -\n",
    "                                           self._pad(self.mean)).pow(2.0),\n",
    "                                  dim=-1 - self._event_ndims)\n",
    "        return mean_cond_var + var_cond_mean\n",
    "\n",
    "    def cdf(self, x):\n",
    "        x = self._pad(x)\n",
    "        cdf_x = self.component_distribution.cdf(x)\n",
    "        mix_prob = self.mixture_distribution.probs\n",
    "\n",
    "        return torch.sum(cdf_x * mix_prob, dim=-1)\n",
    "\n",
    "\n",
    "    def log_prob(self, x):\n",
    "        x = self._pad(x)\n",
    "        log_prob_x = self.component_distribution.log_prob(x)  # [S, B, k]\n",
    "        log_mix_prob = torch.log_softmax(self.mixture_distribution.logits,\n",
    "                                         dim=-1)  # [B, k]\n",
    "        return torch.logsumexp(log_prob_x + log_mix_prob, dim=-1)  # [S, B]\n",
    "\n",
    "\n",
    "    def sample(self, sample_shape=torch.Size()):\n",
    "        with torch.no_grad():\n",
    "            sample_len = len(sample_shape)\n",
    "            batch_len = len(self.batch_shape)\n",
    "            gather_dim = sample_len + batch_len\n",
    "            es = self.event_shape\n",
    "\n",
    "            # mixture samples [n, B]\n",
    "            mix_sample = self.mixture_distribution.sample(sample_shape)\n",
    "            mix_shape = mix_sample.shape\n",
    "\n",
    "            # component samples [n, B, k, E]\n",
    "            comp_samples = self.component_distribution.sample(sample_shape)\n",
    "\n",
    "            # Gather along the k dimension\n",
    "            mix_sample_r = mix_sample.reshape(\n",
    "                mix_shape + torch.Size([1] * (len(es) + 1)))\n",
    "            mix_sample_r = mix_sample_r.repeat(\n",
    "                torch.Size([1] * len(mix_shape)) + torch.Size([1]) + es)\n",
    "\n",
    "            samples = torch.gather(comp_samples, gather_dim, mix_sample_r)\n",
    "            return samples.squeeze(gather_dim)\n",
    "\n",
    "\n",
    "    def _pad(self, x):\n",
    "        return x.unsqueeze(-1 - self._event_ndims)\n",
    "\n",
    "    def _pad_mixture_dimensions(self, x):\n",
    "        dist_batch_ndims = self.batch_shape.numel()\n",
    "        cat_batch_ndims = self.mixture_distribution.batch_shape.numel()\n",
    "        pad_ndims = 0 if cat_batch_ndims == 1 else \\\n",
    "            dist_batch_ndims - cat_batch_ndims\n",
    "        xs = x.shape\n",
    "        x = x.reshape(xs[:-1] + torch.Size(pad_ndims * [1]) +\n",
    "                      xs[-1:] + torch.Size(self._event_ndims * [1]))\n",
    "        return x\n",
    "\n",
    "    def __repr__(self):\n",
    "        args_string = '\\n  {},\\n  {}'.format(self.mixture_distribution,\n",
    "                                             self.component_distribution)\n",
    "        return 'MixtureSameFamily' + '(' + args_string + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix = torch.distributions.categorical.Categorical(torch.ones(5,))\n",
    "comp = torch.distributions.normal.Normal(torch.randn(5,), torch.rand(5,))\n",
    "gmm = MixtureSameFamily(mix, comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix2 = torch.distributions.categorical.Categorical(torch.ones(2,))\n",
    "comp2 = torch.distributions.normal.Normal(torch.randn(2,), torch.rand(2,))\n",
    "gmm2 = MixtureSameFamily(mix2, comp2)\n",
    "\n",
    "\n",
    "mix3 = torch.distributions.categorical.Categorical(torch.rand(3,))\n",
    "comp3 = torch.distributions.normal.Normal(torch.randn(3,), torch.rand(3,))\n",
    "gmm3 = MixtureSameFamily(mix3, comp3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_dist = []\n",
    "for i in range(100): \n",
    "    x = torch.rand(500,1)\n",
    "    set_dist.append(x)\n",
    "    \n",
    "for i in range(35): \n",
    "    m = torch.distributions.beta.Beta(torch.tensor([.5]), torch.tensor([.5]))\n",
    "    x = m.sample([500])\n",
    "    set_dist.append(x)\n",
    "    \n",
    "for i in range(35): \n",
    "    m = torch.distributions.beta.Beta(torch.tensor([.7]), torch.tensor([.3]))\n",
    "    x = m.sample([500])\n",
    "    set_dist.append(x)\n",
    "    \n",
    "for i in range(40): \n",
    "    m = torch.distributions.beta.Beta(torch.tensor([.2]), torch.tensor([.7]))\n",
    "    x = m.sample([500])\n",
    "    set_dist.append(x)\n",
    "    \n",
    "for i in range(50): \n",
    "    m = torch.distributions.exponential.Exponential(torch.tensor([1.5]))\n",
    "    x = m.sample([500])\n",
    "    set_dist.append(x)\n",
    "    \n",
    "for i in range(50): \n",
    "    m = torch.distributions.exponential.Exponential(torch.tensor([2.5]))\n",
    "    x = m.sample([500])\n",
    "    set_dist.append(x)\n",
    "    \n",
    "for i in range(100): \n",
    "    m = torch.distributions.gamma.Gamma(torch.tensor([1.0]), torch.tensor([1.5]))\n",
    "    x = m.sample([500])\n",
    "    set_dist.append(x)\n",
    "    \n",
    "for i in range(40): \n",
    "    m = torch.distributions.laplace.Laplace(torch.tensor([1.0]), torch.tensor([1.5]))\n",
    "    x = m.sample([500])\n",
    "    set_dist.append(x)\n",
    "    \n",
    "for i in range(59): \n",
    "    m = torch.distributions.laplace.Laplace(torch.tensor([.5]), torch.tensor([1.0]))\n",
    "    x = m.sample([500])\n",
    "    set_dist.append(x)\n",
    "    \n",
    "for i in range(100): \n",
    "    m = torch.distributions.log_normal.LogNormal(torch.tensor([0.0]), torch.tensor([0.5]))\n",
    "    x = m.sample([500])\n",
    "    set_dist.append(x)   \n",
    "\n",
    "    \n",
    "for i in range(59): \n",
    "    m = torch.distributions.normal.Normal(torch.tensor([0.0]), torch.tensor([1.0]))\n",
    "    x = m.sample([500])\n",
    "    set_dist.append(x)   \n",
    "\n",
    "for i in range(50): \n",
    "    m = torch.distributions.normal.Normal(torch.tensor([0.3]), torch.tensor([0.5]))\n",
    "    x = m.sample([500])\n",
    "    set_dist.append(x)   \n",
    "    \n",
    "    \n",
    "for i in range(100): \n",
    "    m = torch.distributions.studentT.StudentT(torch.tensor([2.0]))\n",
    "    x = m.sample([500])\n",
    "    set_dist.append(x) \n",
    "    \n",
    "for i in range(100): \n",
    "    x = (gmm.sample([500])).view(-1,1)\n",
    "    set_dist.append(x) \n",
    "    \n",
    "for i in range(100): \n",
    "    x = (gmm2.sample([500])).view(-1,1)\n",
    "    set_dist.append(x) \n",
    "    \n",
    "for i in range(100): \n",
    "    x = (gmm3.sample([500])).view(-1,1)\n",
    "    set_dist.append(x) \n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_dist = torch.stack(set_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1118, 500, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.rand(2, 100, 1)\n",
    "# y = torch.rand(2, 100, 1)\n",
    "# Define a Sinkhorn (~Wasserstein) loss between sampled measures\n",
    "loss = SamplesLoss(loss=\"sinkhorn\", p=1, blur=.005)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepSet(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, set_features):\n",
    "        super(DeepSet, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = set_features\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Linear(in_features, 50),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Linear(50, 100),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Linear(100, set_features)\n",
    "        )\n",
    "\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(set_features, 30),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Linear(30, 30),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Linear(30, 10),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Linear(10, 2),\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, input):\n",
    "        x = input\n",
    "        x = self.feature_extractor(x)\n",
    "        x = x.sum(dim=1)\n",
    "        x = self.regressor(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinkhornDistance(nn.Module):\n",
    "    r\"\"\"\n",
    "    Given two empirical measures each with :math:`P_1` locations\n",
    "    :math:`x\\in\\mathbb{R}^{D_1}` and :math:`P_2` locations :math:`y\\in\\mathbb{R}^{D_2}`,\n",
    "    outputs an approximation of the regularized OT cost for point clouds.\n",
    "    Args:\n",
    "        eps (float): regularization coefficient\n",
    "        max_iter (int): maximum number of Sinkhorn iterations\n",
    "        reduction (string, optional): Specifies the reduction to apply to the output:\n",
    "            'none' | 'mean' | 'sum'. 'none': no reduction will be applied,\n",
    "            'mean': the sum of the output will be divided by the number of\n",
    "            elements in the output, 'sum': the output will be summed. Default: 'none'\n",
    "    Shape:\n",
    "        - Input: :math:`(N, P_1, D_1)`, :math:`(N, P_2, D_2)`\n",
    "        - Output: :math:`(N)` or :math:`()`, depending on `reduction`\n",
    "    \"\"\"\n",
    "    def __init__(self, eps, max_iter, reduction='none'):\n",
    "        super(SinkhornDistance, self).__init__()\n",
    "        self.eps = eps\n",
    "        self.max_iter = max_iter\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        # The Sinkhorn algorithm takes as input three variables :\n",
    "        C = self._cost_matrix(x, y)  # Wasserstein cost function\n",
    "        x_points = x.shape[-2]\n",
    "        y_points = y.shape[-2]\n",
    "        if x.dim() == 2:\n",
    "            batch_size = 1\n",
    "        else:\n",
    "            batch_size = x.shape[0]\n",
    "\n",
    "        # both marginals are fixed with equal weights\n",
    "        mu = torch.empty(batch_size, x_points, dtype=torch.float,\n",
    "                         requires_grad=False).fill_(1.0 / x_points).to(device).squeeze()\n",
    "        nu = torch.empty(batch_size, y_points, dtype=torch.float,\n",
    "                         requires_grad=False).fill_(1.0 / y_points).to(device).squeeze()\n",
    "\n",
    "        u = torch.zeros_like(mu).to(device)\n",
    "        v = torch.zeros_like(nu).to(device)\n",
    "        # To check if algorithm terminates because of threshold\n",
    "        # or max iterations reached\n",
    "        actual_nits = 0\n",
    "        # Stopping criterion\n",
    "        thresh = 1e-1\n",
    "\n",
    "        # Sinkhorn iterations\n",
    "        for i in range(self.max_iter):\n",
    "            u1 = u  # useful to check the update\n",
    "            u = self.eps * (torch.log(mu+1e-8) - torch.logsumexp(self.M(C, u, v), dim=-1)) + u\n",
    "            v = self.eps * (torch.log(nu+1e-8) - torch.logsumexp(self.M(C, u, v).transpose(-2, -1), dim=-1)) + v\n",
    "            err = (u - u1).abs().sum(-1).mean()\n",
    "\n",
    "            actual_nits += 1\n",
    "            if err.item() < thresh:\n",
    "                break\n",
    "\n",
    "        U, V = u, v\n",
    "        # Transport plan pi = diag(a)*K*diag(b)\n",
    "        pi = torch.exp(self.M(C, U, V))\n",
    "        # Sinkhorn distance\n",
    "        cost = torch.sum(pi * C, dim=(-2, -1))\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            cost = cost.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            cost = cost.sum()\n",
    "\n",
    "      #  return cost, pi, C\n",
    "        return cost\n",
    "\n",
    "    def M(self, C, u, v):\n",
    "        \"Modified cost for logarithmic updates\"\n",
    "        \"$M_{ij} = (-c_{ij} + u_i + v_j) / \\epsilon$\"\n",
    "        return (-C + u.unsqueeze(-1) + v.unsqueeze(-2)) / self.eps\n",
    "\n",
    "    @staticmethod\n",
    "    def _cost_matrix(x, y, p=1):\n",
    "        \"Returns the matrix of $|x_i-y_j|^p$.\"\n",
    "        x_col = x.unsqueeze(-2)\n",
    "        y_lin = y.unsqueeze(-3)\n",
    "        C = torch.sum((torch.abs(x_col - y_lin)) ** p, -1)\n",
    "        return C\n",
    "\n",
    "    @staticmethod\n",
    "    def ave(u, u1, tau):\n",
    "        \"Barycenter subroutine, used by kinetic acceleration through extrapolation.\"\n",
    "        return tau * u + (1 - tau) * u1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sinkhorn = SinkhornDistance(eps=0.1, max_iter=100, reduction=None).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data.float()\n",
    "        \n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        \n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "           \n",
    "        return x\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset(set_dist)\n",
    "loader = DataLoader(dataset, batch_size = 12, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepSet(\n",
       "  (feature_extractor): Sequential(\n",
       "    (0): Linear(in_features=1, out_features=50, bias=True)\n",
       "    (1): ELU(alpha=1.0, inplace=True)\n",
       "    (2): Linear(in_features=50, out_features=100, bias=True)\n",
       "    (3): ELU(alpha=1.0, inplace=True)\n",
       "    (4): Linear(in_features=100, out_features=36, bias=True)\n",
       "  )\n",
       "  (regressor): Sequential(\n",
       "    (0): Linear(in_features=36, out_features=30, bias=True)\n",
       "    (1): ELU(alpha=1.0, inplace=True)\n",
       "    (2): Linear(in_features=30, out_features=30, bias=True)\n",
       "    (3): ELU(alpha=1.0, inplace=True)\n",
       "    (4): Linear(in_features=30, out_features=10, bias=True)\n",
       "    (5): ELU(alpha=1.0, inplace=True)\n",
       "    (6): Linear(in_features=10, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = DeepSet(1, 36).to(device)\n",
    "optimizer_encoder = torch.optim.Adam(encoder.parameters(), lr=0.001)\n",
    "\n",
    "# checkpoint = torch.load('autoencoder_encoder.pt')\n",
    "# encoder.load_state_dict(checkpoint['model_state_dict'])\n",
    "# optimizer_encoder.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# loss = checkpoint['loss']\n",
    "\n",
    "# # model.load_state_dict(torch.load('deepset_dist_flat1.pkl'))\n",
    "# encoder.train()\n",
    "# encoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPDecoder(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels, set_size):\n",
    "        super().__init__()\n",
    "        self.output_channels = output_channels\n",
    "        self.input_channels = input_channels\n",
    "      \n",
    "        self.set_size = set_size\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_channels, 10),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Linear(10, 30),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Dropout(p=.5),\n",
    "            nn.Linear(30, 30),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Dropout(p=.5),\n",
    "            nn.Linear(30, 36),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Dropout(p=.5),\n",
    "            nn.Linear(36, 100),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Linear(100, 256),\n",
    "            nn.Dropout(p=.5),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Linear(256, output_channels*set_size)\n",
    "        \n",
    "        )\n",
    "        \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.model(x)\n",
    "        x = x.view(x.size(0), self.set_size, self.output_channels)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPDecoder(\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=2, out_features=10, bias=True)\n",
       "    (1): ELU(alpha=1.0, inplace=True)\n",
       "    (2): Linear(in_features=10, out_features=30, bias=True)\n",
       "    (3): ELU(alpha=1.0, inplace=True)\n",
       "    (4): Dropout(p=0.5, inplace=False)\n",
       "    (5): Linear(in_features=30, out_features=30, bias=True)\n",
       "    (6): ELU(alpha=1.0, inplace=True)\n",
       "    (7): Dropout(p=0.5, inplace=False)\n",
       "    (8): Linear(in_features=30, out_features=36, bias=True)\n",
       "    (9): ELU(alpha=1.0, inplace=True)\n",
       "    (10): Dropout(p=0.5, inplace=False)\n",
       "    (11): Linear(in_features=36, out_features=100, bias=True)\n",
       "    (12): ELU(alpha=1.0, inplace=True)\n",
       "    (13): Linear(in_features=100, out_features=256, bias=True)\n",
       "    (14): Dropout(p=0.5, inplace=False)\n",
       "    (15): ELU(alpha=1.0, inplace=True)\n",
       "    (16): Linear(in_features=256, out_features=500, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = MLPDecoder(2,1,500)\n",
    "optimizer_decoder = torch.optim.Adam(decoder.parameters(), lr=0.001, weight_decay=.001)\n",
    "# checkpoint = torch.load('autoencoder_decoder.pt')\n",
    "# decoder.load_state_dict(checkpoint['model_state_dict'])\n",
    "# optimizer_decoder.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# loss = checkpoint['loss']\n",
    "\n",
    "# decoder.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(batch, n_data, a, y, y_a, y_translate):\n",
    "    loss = [0,0,0]\n",
    "    y_norm = torch.pdist(y)\n",
    "    n_data_pairwise_1 = []\n",
    "    n_data_pairwise_2 = []\n",
    "    for i in range(len(batch)):\n",
    "        for j in range(i+1,len(batch)):\n",
    "            n_data_pairwise_1.append(n_data[i])\n",
    "            n_data_pairwise_2.append(n_data[j])\n",
    "    n_data_pairwise_1 = torch.stack(n_data_pairwise_1)\n",
    "    n_data_pairwise_2 = torch.stack(n_data_pairwise_2)\n",
    "    w_norm = sinkhorn(n_data_pairwise_2, n_data_pairwise_1)\n",
    "    y_a_norm = torch.pdist(y_a)\n",
    "    y_translate_norm = torch.pdist(y_translate)\n",
    "    loss[0] = (y_norm - w_norm).abs().sum()\n",
    "    loss[1] = ((y_a_norm - a * y_norm) ** 2).sum()\n",
    "    loss[2] = ((y_translate_norm - y_norm) ** 2).sum()\n",
    "    loss = sum(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 650\n",
    "running_loss = []\n",
    "for t in range(num_epochs):\n",
    "    for n_batch, batch in enumerate(loader):\n",
    "        n_data = Variable(batch.to(device), requires_grad=True)\n",
    "        a = torch.rand(1).to(device)\n",
    "        b = torch.rand(1).to(device)\n",
    "       \n",
    "    \n",
    "        optimizer_encoder.zero_grad()\n",
    "        optimizer_decoder.zero_grad()\n",
    "        y = encoder(n_data)\n",
    "        y_a = encoder(a*n_data)\n",
    "        y_translate = encoder(n_data + b)\n",
    "        \n",
    "        w = torch.empty(y.shape)\n",
    "        noise = Variable(nn.init.normal_(w, mean=0.0, std=.001), requires_grad=True)\n",
    "        z = decoder(y+noise)\n",
    "        \n",
    "       # loss_encoder = 0\n",
    "        loss_decoder = 0\n",
    "       \n",
    "        for i in range(len(batch)):\n",
    "            loss_decoder += loss(z[i], n_data[i])**2\n",
    "            loss_decoder = loss_decoder/len(batch)\n",
    "            \n",
    "#             for j in range(i+1,len(batch)):\n",
    "                \n",
    "#                 y_ij = torch.norm(y[i]-y[j], p=2)\n",
    "#                 w_ij = sinkhorn(n_data[i],n_data[j]) \n",
    "                \n",
    "#                 ya_ij = torch.norm(y_a[i]-y_a[j], p=2)\n",
    "#                 y_translate_ij = torch.norm(y_translate[i]-y_translate[j], p=2)\n",
    "                \n",
    "#                 diff_translate_ij = torch.norm(y_translate[i]-y[j], p=2)**2\n",
    "                \n",
    "    \n",
    "#                 loss_encoder += torch.norm(y_ij-w_ij, p=2) + (ya_ij-a*y_ij)**2 + (y_translate_ij- y_ij)**2\n",
    "                \n",
    "#                 del w_ij\n",
    "#         #TODO FIX THE LAST TERMS WITH PAIRWISE DISTANCES (SEE PYTORCH CODE)\n",
    "        \n",
    "        \n",
    "        loss_encoder = calculate_loss(batch, n_data, a, y, y_a, y_translate)/(len(batch)*(len(batch)-1)/2)\n",
    "    \n",
    "        \n",
    "        loss_batch = loss_encoder + loss_decoder\n",
    "       \n",
    "        loss_batch.backward()\n",
    "       \n",
    "        optimizer_decoder.step()\n",
    "        optimizer_encoder.step()\n",
    "    \n",
    "        \n",
    "    running_loss.append(loss_batch)\n",
    "    print(loss_batch)\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(running_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0.0823], grad_fn=<AddBackward0>),\n",
       " tensor([0.1545], grad_fn=<AddBackward0>),\n",
       " tensor([0.6018], grad_fn=<AddBackward0>),\n",
       " tensor([0.7524], grad_fn=<AddBackward0>),\n",
       " tensor([0.1143], grad_fn=<AddBackward0>),\n",
       " tensor([0.6857], grad_fn=<AddBackward0>),\n",
       " tensor([0.0833], grad_fn=<AddBackward0>),\n",
       " tensor([0.0891], grad_fn=<AddBackward0>),\n",
       " tensor([0.5008], grad_fn=<AddBackward0>),\n",
       " tensor([0.3427], grad_fn=<AddBackward0>),\n",
       " tensor([0.1139], grad_fn=<AddBackward0>),\n",
       " tensor([0.0571], grad_fn=<AddBackward0>),\n",
       " tensor([0.1046], grad_fn=<AddBackward0>),\n",
       " tensor([0.9911], grad_fn=<AddBackward0>),\n",
       " tensor([0.7912], grad_fn=<AddBackward0>),\n",
       " tensor([0.2586], grad_fn=<AddBackward0>),\n",
       " tensor([0.0984], grad_fn=<AddBackward0>),\n",
       " tensor([0.4491], grad_fn=<AddBackward0>),\n",
       " tensor([0.1116], grad_fn=<AddBackward0>),\n",
       " tensor([0.2526], grad_fn=<AddBackward0>),\n",
       " tensor([0.2025], grad_fn=<AddBackward0>),\n",
       " tensor([0.1162], grad_fn=<AddBackward0>),\n",
       " tensor([0.3517], grad_fn=<AddBackward0>),\n",
       " tensor([0.1983], grad_fn=<AddBackward0>),\n",
       " tensor([0.3041], grad_fn=<AddBackward0>),\n",
       " tensor([0.5836], grad_fn=<AddBackward0>),\n",
       " tensor([0.1261], grad_fn=<AddBackward0>),\n",
       " tensor([0.0473], grad_fn=<AddBackward0>),\n",
       " tensor([0.1294], grad_fn=<AddBackward0>),\n",
       " tensor([0.1183], grad_fn=<AddBackward0>),\n",
       " tensor([0.4401], grad_fn=<AddBackward0>),\n",
       " tensor([0.0792], grad_fn=<AddBackward0>),\n",
       " tensor([0.1490], grad_fn=<AddBackward0>),\n",
       " tensor([0.3326], grad_fn=<AddBackward0>),\n",
       " tensor([1.0131], grad_fn=<AddBackward0>),\n",
       " tensor([0.0969], grad_fn=<AddBackward0>),\n",
       " tensor([0.0683], grad_fn=<AddBackward0>),\n",
       " tensor([0.1720], grad_fn=<AddBackward0>),\n",
       " tensor([0.2184], grad_fn=<AddBackward0>),\n",
       " tensor([0.3210], grad_fn=<AddBackward0>),\n",
       " tensor([0.1435], grad_fn=<AddBackward0>),\n",
       " tensor([0.1260], grad_fn=<AddBackward0>),\n",
       " tensor([0.5822], grad_fn=<AddBackward0>),\n",
       " tensor([0.0775], grad_fn=<AddBackward0>),\n",
       " tensor([0.1429], grad_fn=<AddBackward0>),\n",
       " tensor([0.0644], grad_fn=<AddBackward0>),\n",
       " tensor([0.2819], grad_fn=<AddBackward0>),\n",
       " tensor([0.5377], grad_fn=<AddBackward0>),\n",
       " tensor([0.0454], grad_fn=<AddBackward0>),\n",
       " tensor([0.1537], grad_fn=<AddBackward0>),\n",
       " tensor([0.1409], grad_fn=<AddBackward0>),\n",
       " tensor([0.0465], grad_fn=<AddBackward0>)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "running_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \n",
    "            'model_state_dict': encoder.state_dict(),\n",
    "            'optimizer_state_dict': optimizer_encoder.state_dict(),\n",
    "            'loss': loss\n",
    "            \n",
    "            }, 'autoencoder_encoder.pt')\n",
    "\n",
    "torch.save({\n",
    "    \n",
    "            'model_state_dict': decoder.state_dict(),\n",
    "            'optimizer_state_dict': optimizer_decoder.state_dict(),\n",
    "            'loss': loss\n",
    "            \n",
    "            }, 'autoencoder_decoder.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.distributions.normal.Normal(torch.tensor([0.0]), torch.tensor([1.0]))\n",
    "x = m.sample([500]).view(1,500,1)\n",
    "y = model(x)\n",
    "z = decoder(y).view(500,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_plot = np.linspace(-3, 3, 1000)[:, np.newaxis]\n",
    "bins = np.linspace(-3, 3, 10)\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, sharex=True, sharey=True)\n",
    "fig.subplots_adjust(hspace=0.05, wspace=0.05)\n",
    "\n",
    "# # histogram 1\n",
    "# ax[0, 0].hist(z.detach().numpy()[:, 0], bins=bins, fc='#AAAAFF', )\n",
    "# ax[0, 0].text(-3.5, 0.31, \"Histogram\")\n",
    "\n",
    "# # histogram 2\n",
    "# ax[0, 1].hist(z.detach().numpy()[:, 0], bins=bins + 0.75, fc='#AAAAFF', )\n",
    "# ax[0, 1].text(-3.5, 0.31, \"Histogram, bins shifted\")\n",
    "\n",
    "# tophat KDE\n",
    "kde = KernelDensity(kernel='tophat', bandwidth=0.002).fit(zo.detach().numpy())\n",
    "log_dens = kde.score_samples(X_plot)\n",
    "ax[1, 0].fill(X_plot[:, 0], np.exp(log_dens), fc='#AAAAFF')\n",
    "ax[1, 0].text(-3.5, 0.31, \"Tophat Kernel Density\")\n",
    "\n",
    "# Gaussian KDE\n",
    "kde = KernelDensity(kernel='gaussian', bandwidth=0.002).fit(zo.detach().numpy())\n",
    "log_dens = kde.score_samples(X_plot)\n",
    "ax[1, 1].fill(X_plot[:, 0], np.exp(log_dens), fc='#AAAAFF')\n",
    "ax[1, 1].text(-3.5, 0.31, \"Gaussian Kernel Density\")\n",
    "\n",
    "for axi in ax.ravel():\n",
    "    axi.plot(X[:, 0], np.full(X.shape[0], -0.01), '+k')\n",
    "    axi.set_xlim(-4, 9)\n",
    "    axi.set_ylim(-0.02, 0.34)\n",
    "\n",
    "# for axi in ax[:, 0]:\n",
    "#     axi.set_ylabel('Normalized Density')\n",
    "\n",
    "for axi in ax[1, :]:\n",
    "    axi.set_xlabel('x')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = torch.zeros(1,500,1)\n",
    "yo = model(o)\n",
    "zo = decoder(yo).view(500,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6218, grad_fn=<StdBackward0>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.std(zo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = torch.distributions.gamma.Gamma(torch.tensor([1.0]), torch.tensor([1.5]))\n",
    "x1 = m.sample([500]).view(1,500,1)\n",
    "y1 = model(x1)\n",
    "z1 = decoder(y1).view(500,1)\n",
    "x2 = x1.view(500,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#More "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
